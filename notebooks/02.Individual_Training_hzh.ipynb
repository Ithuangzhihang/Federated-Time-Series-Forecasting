{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da638ca",
   "metadata": {},
   "source": [
    "### In this notebook we perform individual training.\n",
    "In individual learning each base station has access only to it's private dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c3fe1f1-1806-43a8-a467-516338fea3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "# 解释：将当前目录的父目录加入到sys.path中，这样就可以在当前目录下导入父目录的模块\n",
    "parent = Path(os.path.abspath(\"\")).resolve().parents[0]\n",
    "if parent not in sys.path:\n",
    "    sys.path.insert(0, str(parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01e170e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15abc428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解释\n",
    "from ml.utils.data_utils import read_data, generate_time_lags, time_to_feature, handle_nans, to_Xy, \\\n",
    "    to_torch_dataset, to_timeseries_rep, assign_statistics, \\\n",
    "    to_train_val, scale_features, get_data_by_area, remove_identifiers, get_exogenous_data_by_area, handle_outliers,read_data_yl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "350c9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.utils.train_utils import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4688fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.models.mlp import MLP\n",
    "from ml.models.rnn import RNN\n",
    "from ml.models.lstm import LSTM\n",
    "from ml.models.gru import GRU\n",
    "from ml.models.cnn import CNN\n",
    "from ml.models.rnn_autoencoder import DualAttentionAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3db1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    # 数据路径\n",
    "    data_path='/home/yanglin/Federated-Time-Series-Forecasting/dataset/yl/train_data.csv',  # 训练集路径\n",
    "    data_path_test='/home/yanglin/Federated-Time-Series-Forecasting/dataset/yl/test_data.csv',  # 测试集路径\n",
    "    test_size=0.2,  # 验证集大小\n",
    "    \n",
    "    # 预测目标\n",
    "    targets=['needs_charging'],  # 需要预测的列\n",
    "    \n",
    "    # 时间序列参数\n",
    "    num_lags=10,  # 输入特征的时间滞后数\n",
    "\n",
    "    # 数据处理参数\n",
    "    identifier='vehicle_id',  # 标识车辆的列名\n",
    "    nan_constant=0,  # 替换NaN值的常数\n",
    "    x_scaler='minmax',  # 特征标准化方法\n",
    "    y_scaler='minmax',  # 目标标准化方法\n",
    "    outlier_detection=None,  # 异常值处理设置为None\n",
    "\n",
    "    # 模型训练参数\n",
    "    criterion='mse',  # 损失函数\n",
    "    epochs=150,  # 最大训练轮数\n",
    "    lr=0.001,  # 学习率\n",
    "    optimizer='adam',  # 优化器\n",
    "    batch_size=128,  # 批量大小\n",
    "    early_stopping=True,  # 是否使用早停机制\n",
    "    patience=50,  # 早停耐心值\n",
    "    max_grad_norm=0.0,  # 梯度裁剪\n",
    "    reg1=0.0,  # L1正则化\n",
    "    reg2=0.0,  # L2正则化\n",
    "    \n",
    "    # 其他设置\n",
    "    plot_history=True,  # 是否绘制训练损失图\n",
    "    cuda=True,  # 是否使用GPU\n",
    "    seed=0,  # 随机种子\n",
    "    assign_stats=None,  # 是否使用统计数据作为外生数据\n",
    "    use_time_features=True  # 是否使用时间特征\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56a743e",
   "metadata": {},
   "source": [
    "> You can define the base station to perform train on the filter_bs parameter and use it in block 12 or you can define the base station to block 12 explicitly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "763c39ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script arguments: Namespace(assign_stats=None, batch_size=128, criterion='mse', cuda=True, data_path='/home/yanglin/Federated-Time-Series-Forecasting/dataset/yl/train_data.csv', data_path_test='/home/yanglin/Federated-Time-Series-Forecasting/dataset/yl/test_data.csv', early_stopping=True, epochs=150, identifier='vehicle_id', lr=0.001, max_grad_norm=0.0, nan_constant=0, num_lags=10, optimizer='adam', outlier_detection=None, patience=50, plot_history=True, reg1=0.0, reg2=0.0, seed=0, targets=['needs_charging'], test_size=0.2, use_time_features=True, x_scaler='minmax', y_scaler='minmax')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Script arguments: {args}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da3431ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch_version 2.3.0\n",
      "args.cuda True\n",
      "torch.cuda.is_available() False\n",
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.version\n",
    "\n",
    "\n",
    "device = \"cuda\" if args.cuda and torch.cuda.is_available() else \"cpu\"\n",
    "print(\"torch_version\",torch.__version__)\n",
    "print(\"args.cuda\",args.cuda)\n",
    "print(\"torch.cuda.is_available()\",torch.cuda.is_available())\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06bb4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection specification 异常值检测:暂时不需要异常值检测因为我们已经处理过\n",
    "# if args.outlier_detection is not None:\n",
    "#     outlier_columns = ['rb_down', 'rb_up', 'down', 'up'] #需要进行异常值检测的列名\n",
    "#     outlier_kwargs = {\"ElBorn\": (10, 90), \"LesCorts\": (10, 90), \"PobleSec\": (5, 95)} #每个键是一个区域的名称，每个值是一个元组，用于指定该区域的异常值检测参数。\"ElBorn\": (10, 90)：表示对于ElBorn区域，异常值检测的阈值是10和90。\n",
    "#     args.outlier_columns = outlier_columns \n",
    "#     args.outlier_kwargs = outlier_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ac1d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all():\n",
    "    # ensure reproducibility 确保结果的可重复性\n",
    "    random.seed(args.seed) #设置Python标准库中的随机数生成器的种子为args.seed。这会影响使用random模块生成的所有随机数。\n",
    "    np.random.seed(args.seed) #设置NumPy库的随机数生成器的种子为args.seed。这会影响使用numpy.random模块生成的所有随机数。\n",
    "    torch.manual_seed(args.seed) #设置PyTorch库的随机数生成器的种子为args.seed。这会影响CPU上的所有PyTorch操作生成的随机数。\n",
    "    torch.cuda.manual_seed_all(args.seed) #设置所有CUDA设备（即GPU）的随机数生成器的种子为args.seed。这会影响在GPU上执行的所有PyTorch操作生成的随机数。\n",
    "    torch.backends.cudnn.deterministic = True #设置CuDNN后端为确定性模式，这意味着CuDNN将使用确定性的算法，从而确保相同的输入始终产生相同的输出。\n",
    "    torch.backends.cudnn.benchmark = False #禁用CuDNN的benchmark模式。启用benchmark模式可能会导致不同的计算选择不同的算法，从而产生不同的结果，因此禁用它可以确保结果的一致性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea3ddd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00543376",
   "metadata": {},
   "source": [
    "### The preprocessing pipeline performed here for the base station specified in filter_bs argument\n",
    "Preprocessing inlcudes:\n",
    "1. NaNs Handling NANs处理\n",
    "2. Outliers Handling 异常值处理\n",
    "3. Scaling Data 数据缩放\n",
    "4. Generating time lags 生成时间滞后\n",
    "5. Generating and importing exogenous data as features (time, statistics) (if applied) 生成和导入外生数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35bc6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def make_preprocessing(filter_data=None): \n",
    "    #本函数接受一个可选参数‘filter_bs’,用于指定要过滤的基站。如果没有提供该参数，则处理所有基站的数据。\n",
    "    \"\"\"Preprocess a given .csv\"\"\"\n",
    "    # read data 使用read_data函数读取指定路径（args.data_path）的CSV数据，并根据filter_bs过滤数据。\n",
    "    df = read_data_yl(args.data_path, filter_data=filter_data)\n",
    "    # # handle nans 使用handle_nans函数处理数据中的缺失值。缺失值将被替换为args.nan_constant指定的常数。\n",
    "    # df = handle_nans(train_data=df, constant=args.nan_constant,\n",
    "    #                  identifier=args.identifier)\n",
    "    # # split to train/validation 将数据集划分为训练集和验证集。具体的划分比例由预先定义的参数决定。\n",
    "    # train_data, val_data = to_train_val(df)\n",
    "    \n",
    "    # # handle outliers (if specified) 如果启用了异常值检测（args.outlier_detection不为None），则使用handle_outliers函数处理训练数据中的异常值。\n",
    "    # if args.outlier_detection is not None:\n",
    "    #     train_data = handle_outliers(df=train_data, columns=args.outlier_columns,\n",
    "    #                                  identifier=args.identifier, kwargs=args.outlier_kwargs)\n",
    "    \n",
    "    # # get X and y 将训练集和验证集中的特征（X）和目标变量（y）分离出来。\n",
    "    # X_train, X_val, y_train, y_val = to_Xy(train_data=train_data, val_data=val_data,\n",
    "    #                                       targets=args.targets)\n",
    "    # # 对特征数据和目标变量分别进行缩放（标准化或归一化），以确保它们在相似的尺度上。缩放方法由args.x_scaler和args.y_scaler指定。\n",
    "    # # scale X\n",
    "    # X_train, X_val, x_scaler = scale_features(train_data=X_train, val_data=X_val,\n",
    "    #                                          scaler=args.x_scaler, identifier=args.identifier)\n",
    "    # # scale y\n",
    "    # y_train, y_val, y_scaler = scale_features(train_data=y_train, val_data=y_val,\n",
    "    #                                          scaler=args.y_scaler, identifier=args.identifier)\n",
    "    \n",
    "    # # generate time lags 生成时间滞后特征，即在时间序列数据中，使用过去若干时间步的数据作为当前时间步的输入特征。\n",
    "    # X_train = generate_time_lags(X_train, args.num_lags)\n",
    "    # X_val = generate_time_lags(X_val, args.num_lags)\n",
    "    # y_train = generate_time_lags(y_train, args.num_lags, is_y=True)\n",
    "    # y_val = generate_time_lags(y_val, args.num_lags, is_y=True)\n",
    "    \n",
    "    # #生成并导入时间特征（如时间戳、日期等）和统计特征（如均值、方差等），作为外生数据特征。\n",
    "    # # get datetime features as exogenous data\n",
    "    # date_time_df_train = time_to_feature(\n",
    "    #     X_train, args.use_time_features, identifier=args.identifier\n",
    "    # )\n",
    "    # date_time_df_val = time_to_feature(\n",
    "    #     X_val, args.use_time_features, identifier=args.identifier\n",
    "    # )\n",
    "    \n",
    "    # # get statistics as exogenous data\n",
    "    # stats_df_train = assign_statistics(X_train, args.assign_stats, args.num_lags,\n",
    "    #                                    targets=args.targets, identifier=args.identifier)\n",
    "    # stats_df_val = assign_statistics(X_val, args.assign_stats, args.num_lags, \n",
    "    #                                    targets=args.targets, identifier=args.identifier)\n",
    "    \n",
    "    # #合并生成的外生特征（时间特征和统计特征），并去除重复的列。如果没有外生特征，则设为None。\n",
    "    # #exogenous_data_train 和 exogenous_data_val如果不为 None，这些是训练集和验证集的外生特征数据。\n",
    "    # # concat the exogenous features (if any) to a single dataframe\n",
    "    # if date_time_df_train is not None or stats_df_train is not None:\n",
    "    #     exogenous_data_train = pd.concat([date_time_df_train, stats_df_train], axis=1)\n",
    "    #     # remove duplicate columns (if any)\n",
    "    #     exogenous_data_train = exogenous_data_train.loc[:, ~exogenous_data_train.columns.duplicated()].copy()\n",
    "    #     assert len(exogenous_data_train) == len(X_train) == len(y_train)\n",
    "    # else:\n",
    "    #     exogenous_data_train = None\n",
    "    # if date_time_df_val is not None or stats_df_val is not None:\n",
    "    #     exogenous_data_val = pd.concat([date_time_df_val, stats_df_val], axis=1)\n",
    "    #     exogenous_data_val = exogenous_data_val.loc[:, ~exogenous_data_val.columns.duplicated()].copy()\n",
    "    #     assert len(exogenous_data_val) == len(X_val) == len(y_val)\n",
    "    # else:\n",
    "    #     exogenous_data_val = None\n",
    "        \n",
    "    # return X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scaler, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66fc93eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO logger 2024-05-29 01:51:13,480 | data_utils.py:53 | Reading data for vehicle ID A032...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '   Navigation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# here exogenous_data_train and val are None.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scaler, y_scaler \u001b[38;5;241m=\u001b[39m \u001b[43mmake_preprocessing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA032\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m, in \u001b[0;36mmake_preprocessing\u001b[0;34m(filter_data)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess a given .csv\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# read data 使用read_data函数读取指定路径（args.data_path）的CSV数据，并根据filter_bs过滤数据。\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mread_data_yl\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/yanglin/Federated-Time-Series-Forecasting/ml/utils/data_utils.py:62\u001b[0m, in \u001b[0;36mread_data_yl\u001b[0;34m(data_path, filter_data)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# 将除 'vehicle_id' 外的所有列转换为 float32 类型，以减少内存占用\u001b[39;00m\n\u001b[1;32m     61\u001b[0m cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvehicle_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 62\u001b[0m df[cols] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/anaconda3/envs/fedtime/lib/python3.8/site-packages/pandas/core/generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6317\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   6319\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m   6320\u001b[0m     ]\n\u001b[1;32m   6322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6323\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6324\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6327\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fedtime/lib/python3.8/site-packages/pandas/core/internals/managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    449\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fedtime/lib/python3.8/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/envs/fedtime/lib/python3.8/site-packages/pandas/core/internals/blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 511\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    515\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fedtime/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    239\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/fedtime/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:187\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    184\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/fedtime/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '   Navigation'"
     ]
    }
   ],
   "source": [
    "# here exogenous_data_train and val are None.\n",
    "X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scaler, y_scaler = make_preprocessing(\n",
    "    filter_data=\"A032\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "9b99c6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rb_up_var_lag-10</th>\n",
       "      <th>rb_up_lag-10</th>\n",
       "      <th>rb_down_var_lag-10</th>\n",
       "      <th>rb_down_lag-10</th>\n",
       "      <th>mcs_up_var_lag-10</th>\n",
       "      <th>mcs_up_lag-10</th>\n",
       "      <th>mcs_down_var_lag-10</th>\n",
       "      <th>mcs_down_lag-10</th>\n",
       "      <th>rnti_count_lag-10</th>\n",
       "      <th>up_lag-10</th>\n",
       "      <th>...</th>\n",
       "      <th>rb_down_var_lag-1</th>\n",
       "      <th>rb_down_lag-1</th>\n",
       "      <th>mcs_up_var_lag-1</th>\n",
       "      <th>mcs_up_lag-1</th>\n",
       "      <th>mcs_down_var_lag-1</th>\n",
       "      <th>mcs_down_lag-1</th>\n",
       "      <th>rnti_count_lag-1</th>\n",
       "      <th>up_lag-1</th>\n",
       "      <th>down_lag-1</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-12 17:32:00</th>\n",
       "      <td>1.083682e-08</td>\n",
       "      <td>0.036054</td>\n",
       "      <td>1.961025e-08</td>\n",
       "      <td>0.109670</td>\n",
       "      <td>0.493544</td>\n",
       "      <td>0.431702</td>\n",
       "      <td>0.459601</td>\n",
       "      <td>0.160269</td>\n",
       "      <td>0.210509</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>...</td>\n",
       "      <td>1.974816e-08</td>\n",
       "      <td>0.114193</td>\n",
       "      <td>0.572030</td>\n",
       "      <td>0.400005</td>\n",
       "      <td>0.460896</td>\n",
       "      <td>0.164719</td>\n",
       "      <td>0.212757</td>\n",
       "      <td>0.018888</td>\n",
       "      <td>0.131219</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 17:34:00</th>\n",
       "      <td>1.061491e-08</td>\n",
       "      <td>0.030426</td>\n",
       "      <td>1.644211e-08</td>\n",
       "      <td>0.098938</td>\n",
       "      <td>0.527483</td>\n",
       "      <td>0.476772</td>\n",
       "      <td>0.392094</td>\n",
       "      <td>0.131085</td>\n",
       "      <td>0.200300</td>\n",
       "      <td>0.018282</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791601e-08</td>\n",
       "      <td>0.105544</td>\n",
       "      <td>0.576015</td>\n",
       "      <td>0.445876</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>0.145817</td>\n",
       "      <td>0.192432</td>\n",
       "      <td>0.014424</td>\n",
       "      <td>0.113276</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 17:36:00</th>\n",
       "      <td>9.109702e-09</td>\n",
       "      <td>0.038901</td>\n",
       "      <td>1.761309e-08</td>\n",
       "      <td>0.106045</td>\n",
       "      <td>0.501063</td>\n",
       "      <td>0.471773</td>\n",
       "      <td>0.453949</td>\n",
       "      <td>0.152725</td>\n",
       "      <td>0.221468</td>\n",
       "      <td>0.019501</td>\n",
       "      <td>...</td>\n",
       "      <td>1.766410e-08</td>\n",
       "      <td>0.101075</td>\n",
       "      <td>0.640010</td>\n",
       "      <td>0.448971</td>\n",
       "      <td>0.387407</td>\n",
       "      <td>0.130386</td>\n",
       "      <td>0.173137</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.101414</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 17:38:00</th>\n",
       "      <td>5.813802e-09</td>\n",
       "      <td>0.026050</td>\n",
       "      <td>1.668480e-08</td>\n",
       "      <td>0.098968</td>\n",
       "      <td>0.499865</td>\n",
       "      <td>0.450949</td>\n",
       "      <td>0.382516</td>\n",
       "      <td>0.129036</td>\n",
       "      <td>0.183768</td>\n",
       "      <td>0.012594</td>\n",
       "      <td>...</td>\n",
       "      <td>1.963081e-08</td>\n",
       "      <td>0.114777</td>\n",
       "      <td>0.534812</td>\n",
       "      <td>0.414812</td>\n",
       "      <td>0.476978</td>\n",
       "      <td>0.171880</td>\n",
       "      <td>0.205545</td>\n",
       "      <td>0.023585</td>\n",
       "      <td>0.141225</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 17:40:00</th>\n",
       "      <td>7.246522e-09</td>\n",
       "      <td>0.028981</td>\n",
       "      <td>1.721707e-08</td>\n",
       "      <td>0.102669</td>\n",
       "      <td>0.535319</td>\n",
       "      <td>0.429488</td>\n",
       "      <td>0.412994</td>\n",
       "      <td>0.139577</td>\n",
       "      <td>0.191964</td>\n",
       "      <td>0.013056</td>\n",
       "      <td>...</td>\n",
       "      <td>1.895823e-08</td>\n",
       "      <td>0.107131</td>\n",
       "      <td>0.547422</td>\n",
       "      <td>0.456544</td>\n",
       "      <td>0.448805</td>\n",
       "      <td>0.157300</td>\n",
       "      <td>0.181567</td>\n",
       "      <td>0.022127</td>\n",
       "      <td>0.125069</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rb_up_var_lag-10  rb_up_lag-10  rb_down_var_lag-10  \\\n",
       "time                                                                      \n",
       "2019-01-12 17:32:00      1.083682e-08      0.036054        1.961025e-08   \n",
       "2019-01-12 17:34:00      1.061491e-08      0.030426        1.644211e-08   \n",
       "2019-01-12 17:36:00      9.109702e-09      0.038901        1.761309e-08   \n",
       "2019-01-12 17:38:00      5.813802e-09      0.026050        1.668480e-08   \n",
       "2019-01-12 17:40:00      7.246522e-09      0.028981        1.721707e-08   \n",
       "\n",
       "                     rb_down_lag-10  mcs_up_var_lag-10  mcs_up_lag-10  \\\n",
       "time                                                                    \n",
       "2019-01-12 17:32:00        0.109670           0.493544       0.431702   \n",
       "2019-01-12 17:34:00        0.098938           0.527483       0.476772   \n",
       "2019-01-12 17:36:00        0.106045           0.501063       0.471773   \n",
       "2019-01-12 17:38:00        0.098968           0.499865       0.450949   \n",
       "2019-01-12 17:40:00        0.102669           0.535319       0.429488   \n",
       "\n",
       "                     mcs_down_var_lag-10  mcs_down_lag-10  rnti_count_lag-10  \\\n",
       "time                                                                           \n",
       "2019-01-12 17:32:00             0.459601         0.160269           0.210509   \n",
       "2019-01-12 17:34:00             0.392094         0.131085           0.200300   \n",
       "2019-01-12 17:36:00             0.453949         0.152725           0.221468   \n",
       "2019-01-12 17:38:00             0.382516         0.129036           0.183768   \n",
       "2019-01-12 17:40:00             0.412994         0.139577           0.191964   \n",
       "\n",
       "                     up_lag-10  ...  rb_down_var_lag-1  rb_down_lag-1  \\\n",
       "time                            ...                                     \n",
       "2019-01-12 17:32:00   0.017705  ...       1.974816e-08       0.114193   \n",
       "2019-01-12 17:34:00   0.018282  ...       1.791601e-08       0.105544   \n",
       "2019-01-12 17:36:00   0.019501  ...       1.766410e-08       0.101075   \n",
       "2019-01-12 17:38:00   0.012594  ...       1.963081e-08       0.114777   \n",
       "2019-01-12 17:40:00   0.013056  ...       1.895823e-08       0.107131   \n",
       "\n",
       "                     mcs_up_var_lag-1  mcs_up_lag-1  mcs_down_var_lag-1  \\\n",
       "time                                                                      \n",
       "2019-01-12 17:32:00          0.572030      0.400005            0.460896   \n",
       "2019-01-12 17:34:00          0.576015      0.445876            0.427184   \n",
       "2019-01-12 17:36:00          0.640010      0.448971            0.387407   \n",
       "2019-01-12 17:38:00          0.534812      0.414812            0.476978   \n",
       "2019-01-12 17:40:00          0.547422      0.456544            0.448805   \n",
       "\n",
       "                     mcs_down_lag-1  rnti_count_lag-1  up_lag-1  down_lag-1  \\\n",
       "time                                                                          \n",
       "2019-01-12 17:32:00        0.164719          0.212757  0.018888    0.131219   \n",
       "2019-01-12 17:34:00        0.145817          0.192432  0.014424    0.113276   \n",
       "2019-01-12 17:36:00        0.130386          0.173137  0.011194    0.101414   \n",
       "2019-01-12 17:38:00        0.171880          0.205545  0.023585    0.141225   \n",
       "2019-01-12 17:40:00        0.157300          0.181567  0.022127    0.125069   \n",
       "\n",
       "                     District  \n",
       "time                           \n",
       "2019-01-12 17:32:00  LesCorts  \n",
       "2019-01-12 17:34:00  LesCorts  \n",
       "2019-01-12 17:36:00  LesCorts  \n",
       "2019-01-12 17:38:00  LesCorts  \n",
       "2019-01-12 17:40:00  LesCorts  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()\n",
    "#time：时间戳，表示数据记录的具体时间\n",
    "#down：下行流量，单位可能是字节\n",
    "#up：上行流量，单位可能是字节\n",
    "#rnti_count：RNTI（Radio Network Temporary Identifier）计数，表示在指定时间内活跃的RNTI数量。\n",
    "#mcs_down：下行调制和编码方案（MCS，Modulation and Coding Scheme）的平均值，表示下行链路的调制和编码效率。\n",
    "#mcs_down_var：下行MCS的方差，表示下行链路调制和编码效率的变化程度\n",
    "#mcs_up：上行调制和编码方案（MCS，Modulation and Coding Scheme）的平均值，表示上行链路的调制和编码效率。\n",
    "#mcs_up_var：上行MCS的方差，表示上行链路调制和编码效率的变化程度\n",
    "#rb_down：下行资源块（RB，Resource Block）的平均值，表示在指定时间内下行链路使用的资源块的平均数量。\n",
    "#rb_down_var：下行资源块的方差，表示下行链路资源块使用数量的变化程度\n",
    "#rb_up：上行资源块（RB，Resource Block）的平均值，表示在指定时间内上行链路使用的资源块的平均数量\n",
    "#rb_up_var：上行资源块的方差，表示上行链路资源块使用数量的变化程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "837bfd70-4962-4c1e-a8dd-4ac5e6ed261e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rb_up_var_lag-10</th>\n",
       "      <th>rb_up_lag-10</th>\n",
       "      <th>rb_down_var_lag-10</th>\n",
       "      <th>rb_down_lag-10</th>\n",
       "      <th>mcs_up_var_lag-10</th>\n",
       "      <th>mcs_up_lag-10</th>\n",
       "      <th>mcs_down_var_lag-10</th>\n",
       "      <th>mcs_down_lag-10</th>\n",
       "      <th>rnti_count_lag-10</th>\n",
       "      <th>up_lag-10</th>\n",
       "      <th>...</th>\n",
       "      <th>rb_down_var_lag-1</th>\n",
       "      <th>rb_down_lag-1</th>\n",
       "      <th>mcs_up_var_lag-1</th>\n",
       "      <th>mcs_up_lag-1</th>\n",
       "      <th>mcs_down_var_lag-1</th>\n",
       "      <th>mcs_down_lag-1</th>\n",
       "      <th>rnti_count_lag-1</th>\n",
       "      <th>up_lag-1</th>\n",
       "      <th>down_lag-1</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-20 09:20:00</th>\n",
       "      <td>4.728611e-09</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>4.323541e-08</td>\n",
       "      <td>0.058302</td>\n",
       "      <td>0.401278</td>\n",
       "      <td>0.501344</td>\n",
       "      <td>0.919491</td>\n",
       "      <td>0.935376</td>\n",
       "      <td>0.123355</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>...</td>\n",
       "      <td>4.402667e-08</td>\n",
       "      <td>0.072691</td>\n",
       "      <td>0.111839</td>\n",
       "      <td>0.444416</td>\n",
       "      <td>0.885758</td>\n",
       "      <td>0.931423</td>\n",
       "      <td>0.154451</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.180818</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 09:22:00</th>\n",
       "      <td>9.995833e-10</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>4.508320e-08</td>\n",
       "      <td>0.056214</td>\n",
       "      <td>0.159144</td>\n",
       "      <td>0.393817</td>\n",
       "      <td>0.841731</td>\n",
       "      <td>0.960886</td>\n",
       "      <td>0.118906</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>...</td>\n",
       "      <td>4.474956e-08</td>\n",
       "      <td>0.109179</td>\n",
       "      <td>0.275191</td>\n",
       "      <td>0.471308</td>\n",
       "      <td>0.877144</td>\n",
       "      <td>0.933492</td>\n",
       "      <td>0.222077</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.264679</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 09:24:00</th>\n",
       "      <td>1.217479e-08</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>4.771216e-08</td>\n",
       "      <td>0.097153</td>\n",
       "      <td>0.301473</td>\n",
       "      <td>0.467948</td>\n",
       "      <td>0.869250</td>\n",
       "      <td>0.931095</td>\n",
       "      <td>0.202079</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>...</td>\n",
       "      <td>4.620672e-08</td>\n",
       "      <td>0.140548</td>\n",
       "      <td>0.407761</td>\n",
       "      <td>0.487723</td>\n",
       "      <td>0.900534</td>\n",
       "      <td>0.947047</td>\n",
       "      <td>0.287079</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.343279</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 09:26:00</th>\n",
       "      <td>9.579305e-09</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>4.462743e-08</td>\n",
       "      <td>0.100799</td>\n",
       "      <td>0.333194</td>\n",
       "      <td>0.519904</td>\n",
       "      <td>0.868349</td>\n",
       "      <td>0.948227</td>\n",
       "      <td>0.202641</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>...</td>\n",
       "      <td>4.512395e-08</td>\n",
       "      <td>0.098633</td>\n",
       "      <td>0.307474</td>\n",
       "      <td>0.474030</td>\n",
       "      <td>0.852834</td>\n",
       "      <td>0.955406</td>\n",
       "      <td>0.203906</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.241753</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 09:28:00</th>\n",
       "      <td>2.505653e-08</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>4.706725e-08</td>\n",
       "      <td>0.135352</td>\n",
       "      <td>0.406647</td>\n",
       "      <td>0.504277</td>\n",
       "      <td>0.900401</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.270641</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>...</td>\n",
       "      <td>4.390479e-08</td>\n",
       "      <td>0.076930</td>\n",
       "      <td>0.214200</td>\n",
       "      <td>0.541009</td>\n",
       "      <td>0.900236</td>\n",
       "      <td>0.940772</td>\n",
       "      <td>0.160727</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rb_up_var_lag-10  rb_up_lag-10  rb_down_var_lag-10  \\\n",
       "time                                                                      \n",
       "2019-01-20 09:20:00      4.728611e-09      0.000378        4.323541e-08   \n",
       "2019-01-20 09:22:00      9.995833e-10      0.000330        4.508320e-08   \n",
       "2019-01-20 09:24:00      1.217479e-08      0.000859        4.771216e-08   \n",
       "2019-01-20 09:26:00      9.579305e-09      0.000850        4.462743e-08   \n",
       "2019-01-20 09:28:00      2.505653e-08      0.001541        4.706725e-08   \n",
       "\n",
       "                     rb_down_lag-10  mcs_up_var_lag-10  mcs_up_lag-10  \\\n",
       "time                                                                    \n",
       "2019-01-20 09:20:00        0.058302           0.401278       0.501344   \n",
       "2019-01-20 09:22:00        0.056214           0.159144       0.393817   \n",
       "2019-01-20 09:24:00        0.097153           0.301473       0.467948   \n",
       "2019-01-20 09:26:00        0.100799           0.333194       0.519904   \n",
       "2019-01-20 09:28:00        0.135352           0.406647       0.504277   \n",
       "\n",
       "                     mcs_down_var_lag-10  mcs_down_lag-10  rnti_count_lag-10  \\\n",
       "time                                                                           \n",
       "2019-01-20 09:20:00             0.919491         0.935376           0.123355   \n",
       "2019-01-20 09:22:00             0.841731         0.960886           0.118906   \n",
       "2019-01-20 09:24:00             0.869250         0.931095           0.202079   \n",
       "2019-01-20 09:26:00             0.868349         0.948227           0.202641   \n",
       "2019-01-20 09:28:00             0.900401         0.945294           0.270641   \n",
       "\n",
       "                     up_lag-10  ...  rb_down_var_lag-1  rb_down_lag-1  \\\n",
       "time                            ...                                     \n",
       "2019-01-20 09:20:00   0.000206  ...       4.402667e-08       0.072691   \n",
       "2019-01-20 09:22:00   0.000160  ...       4.474956e-08       0.109179   \n",
       "2019-01-20 09:24:00   0.000558  ...       4.620672e-08       0.140548   \n",
       "2019-01-20 09:26:00   0.000568  ...       4.512395e-08       0.098633   \n",
       "2019-01-20 09:28:00   0.001207  ...       4.390479e-08       0.076930   \n",
       "\n",
       "                     mcs_up_var_lag-1  mcs_up_lag-1  mcs_down_var_lag-1  \\\n",
       "time                                                                      \n",
       "2019-01-20 09:20:00          0.111839      0.444416            0.885758   \n",
       "2019-01-20 09:22:00          0.275191      0.471308            0.877144   \n",
       "2019-01-20 09:24:00          0.407761      0.487723            0.900534   \n",
       "2019-01-20 09:26:00          0.307474      0.474030            0.852834   \n",
       "2019-01-20 09:28:00          0.214200      0.541009            0.900236   \n",
       "\n",
       "                     mcs_down_lag-1  rnti_count_lag-1  up_lag-1  down_lag-1  \\\n",
       "time                                                                          \n",
       "2019-01-20 09:20:00        0.931423          0.154451  0.000336    0.180818   \n",
       "2019-01-20 09:22:00        0.933492          0.222077  0.000623    0.264679   \n",
       "2019-01-20 09:24:00        0.947047          0.287079  0.000887    0.343279   \n",
       "2019-01-20 09:26:00        0.955406          0.203906  0.000384    0.241753   \n",
       "2019-01-20 09:28:00        0.940772          0.160727  0.000374    0.191878   \n",
       "\n",
       "                     District  \n",
       "time                           \n",
       "2019-01-20 09:20:00  LesCorts  \n",
       "2019-01-20 09:22:00  LesCorts  \n",
       "2019-01-20 09:24:00  LesCorts  \n",
       "2019-01-20 09:26:00  LesCorts  \n",
       "2019-01-20 09:28:00  LesCorts  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#解释\n",
    "X_val.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "ec22537f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rnti_count</th>\n",
       "      <th>rb_down</th>\n",
       "      <th>rb_up</th>\n",
       "      <th>down</th>\n",
       "      <th>up</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-12 17:32:00</th>\n",
       "      <td>0.192432</td>\n",
       "      <td>0.105544</td>\n",
       "      <td>0.033785</td>\n",
       "      <td>0.113276</td>\n",
       "      <td>0.014424</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 17:34:00</th>\n",
       "      <td>0.173137</td>\n",
       "      <td>0.101075</td>\n",
       "      <td>0.025216</td>\n",
       "      <td>0.101414</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 17:36:00</th>\n",
       "      <td>0.205545</td>\n",
       "      <td>0.114777</td>\n",
       "      <td>0.060088</td>\n",
       "      <td>0.141225</td>\n",
       "      <td>0.023585</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 17:38:00</th>\n",
       "      <td>0.181567</td>\n",
       "      <td>0.107131</td>\n",
       "      <td>0.042592</td>\n",
       "      <td>0.125069</td>\n",
       "      <td>0.022127</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 17:40:00</th>\n",
       "      <td>0.175900</td>\n",
       "      <td>0.101726</td>\n",
       "      <td>0.023463</td>\n",
       "      <td>0.107920</td>\n",
       "      <td>0.011213</td>\n",
       "      <td>LesCorts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rnti_count   rb_down     rb_up      down        up  \\\n",
       "time                                                                      \n",
       "2019-01-12 17:32:00    0.192432  0.105544  0.033785  0.113276  0.014424   \n",
       "2019-01-12 17:34:00    0.173137  0.101075  0.025216  0.101414  0.011194   \n",
       "2019-01-12 17:36:00    0.205545  0.114777  0.060088  0.141225  0.023585   \n",
       "2019-01-12 17:38:00    0.181567  0.107131  0.042592  0.125069  0.022127   \n",
       "2019-01-12 17:40:00    0.175900  0.101726  0.023463  0.107920  0.011213   \n",
       "\n",
       "                     District  \n",
       "time                           \n",
       "2019-01-12 17:32:00  LesCorts  \n",
       "2019-01-12 17:34:00  LesCorts  \n",
       "2019-01-12 17:36:00  LesCorts  \n",
       "2019-01-12 17:38:00  LesCorts  \n",
       "2019-01-12 17:40:00  LesCorts  "
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "367c2b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MinMaxScaler(), MinMaxScaler())"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaler, y_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488a9c30",
   "metadata": {},
   "source": [
    "### Postprocessing Stage\n",
    "\n",
    "In this stage we transform data in a way that can be fed into ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "c417082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_postprocessing(X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scaler, y_scaler):\n",
    "    #X_train, X_val: 训练集和验证集的特征数据。\n",
    "    #y_train, y_val: 训练集和验证集的目标数据。\n",
    "    #exogenous_data_train, exogenous_data_val: 训练集和验证集的外生数据。\n",
    "    #x_scaler, y_scaler: 特征数据和目标数据的缩放器。\n",
    "    \"\"\"Make data ready to be fed into ml algorithms\"\"\"\n",
    "    # if there are more than one specified areas, get the data per area \n",
    "    #检查训练数据集中是否有多个不同的区域（由 args.identifier 标识）。如果有多个区域，则调用 get_data_by_area 函数将数据按区域分割。\n",
    "    if X_train[args.identifier].nunique() != 1:\n",
    "        area_X_train, area_X_val, area_y_train, area_y_val = get_data_by_area(X_train, X_val,\n",
    "                                                                              y_train, y_val, \n",
    "                                                                              identifier=args.identifier)\n",
    "    else:\n",
    "        area_X_train, area_X_val, area_y_train, area_y_val = None, None, None, None\n",
    "\n",
    "    # Get the exogenous data per area. 获取每个区域的外生数据 如果存在外生数据，则将其按区域分割。\n",
    "    if exogenous_data_train is not None:\n",
    "        exogenous_data_train, exogenous_data_val = get_exogenous_data_by_area(exogenous_data_train,\n",
    "                                                                              exogenous_data_val)\n",
    "    # transform to np 将区域划分的数据转换为 NumPy 数组，并移除标识符列（如区域名称）。\n",
    "    if area_X_train is not None:\n",
    "        for area in area_X_train:\n",
    "            tmp_X_train, tmp_y_train, tmp_X_val, tmp_y_val = remove_identifiers(\n",
    "                area_X_train[area], area_y_train[area], area_X_val[area], area_y_val[area])\n",
    "            tmp_X_train, tmp_y_train = tmp_X_train.to_numpy(), tmp_y_train.to_numpy()\n",
    "            tmp_X_val, tmp_y_val = tmp_X_val.to_numpy(), tmp_y_val.to_numpy()\n",
    "            area_X_train[area] = tmp_X_train\n",
    "            area_X_val[area] = tmp_X_val\n",
    "            area_y_train[area] = tmp_y_train\n",
    "            area_y_val[area] = tmp_y_val\n",
    "    \n",
    "    if exogenous_data_train is not None:\n",
    "        for area in exogenous_data_train:\n",
    "            exogenous_data_train[area] = exogenous_data_train[area].to_numpy()\n",
    "            exogenous_data_val[area] = exogenous_data_val[area].to_numpy()\n",
    "    \n",
    "    # remove identifiers from features, targets 对整体数据集，移除标识符列，并确保训练集和验证集的特征列数相同。\n",
    "    X_train, y_train, X_val, y_val = remove_identifiers(X_train, y_train, X_val, y_val)\n",
    "    assert len(X_train.columns) == len(X_val.columns)\n",
    "    #计算特征数量，这里每个特征都有多个滞后期，所以除以滞后期的数量\n",
    "    num_features = len(X_train.columns) // args.num_lags\n",
    "    \n",
    "    # to timeseries representation 将特征数据转换为时间序列表示，即构建时间滞后的特征集\n",
    "    X_train = to_timeseries_rep(X_train.to_numpy(), num_lags=args.num_lags,\n",
    "                                            num_features=num_features)\n",
    "    X_val = to_timeseries_rep(X_val.to_numpy(), num_lags=args.num_lags,\n",
    "                                          num_features=num_features)\n",
    "    \n",
    "    if area_X_train is not None:\n",
    "        area_X_train = to_timeseries_rep(area_X_train, num_lags=args.num_lags,\n",
    "                                                     num_features=num_features)\n",
    "        area_X_val = to_timeseries_rep(area_X_val, num_lags=args.num_lags,\n",
    "                                                   num_features=num_features)\n",
    "    \n",
    "    # transform targets to numpy 将目标数据转换为 NumPy 数组\n",
    "    y_train, y_val = y_train.to_numpy(), y_val.to_numpy()\n",
    "    \n",
    "    # centralized (all) learning specific 在集中学习的情况下，将所有区域的外生数据合并成一个数据集\n",
    "    if not args.filter_bs and exogenous_data_train is not None:\n",
    "        exogenous_data_train_combined, exogenous_data_val_combined = [], []\n",
    "        for area in exogenous_data_train:\n",
    "            exogenous_data_train_combined.extend(exogenous_data_train[area])\n",
    "            exogenous_data_val_combined.extend(exogenous_data_val[area])\n",
    "        exogenous_data_train_combined = np.stack(exogenous_data_train_combined)\n",
    "        exogenous_data_val_combined = np.stack(exogenous_data_val_combined)\n",
    "        exogenous_data_train[\"all\"] = exogenous_data_train_combined\n",
    "        exogenous_data_val[\"all\"] = exogenous_data_val_combined\n",
    "    return X_train, X_val, y_train, y_val, area_X_train, area_X_val, area_y_train, area_y_val, exogenous_data_train, exogenous_data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "00c59dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, area_X_train, area_X_val, area_y_train, area_y_val, exogenous_data_train, exogenous_data_val = make_postprocessing(X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scaler, y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "9171667b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.08368177e-08],\n",
       "         [3.60536501e-02],\n",
       "         [1.96102530e-08],\n",
       "         [1.09670356e-01],\n",
       "         [4.93544310e-01],\n",
       "         [4.31701750e-01],\n",
       "         [4.59600508e-01],\n",
       "         [1.60269260e-01],\n",
       "         [2.10509062e-01],\n",
       "         [1.77047513e-02],\n",
       "         [1.29703119e-01]],\n",
       "\n",
       "        [[1.06149072e-08],\n",
       "         [3.04260999e-02],\n",
       "         [1.64421117e-08],\n",
       "         [9.89375487e-02],\n",
       "         [5.27482629e-01],\n",
       "         [4.76772249e-01],\n",
       "         [3.92093986e-01],\n",
       "         [1.31084532e-01],\n",
       "         [2.00299725e-01],\n",
       "         [1.82819255e-02],\n",
       "         [9.46676582e-02]],\n",
       "\n",
       "        [[9.10970233e-09],\n",
       "         [3.89005616e-02],\n",
       "         [1.76130861e-08],\n",
       "         [1.06044851e-01],\n",
       "         [5.01062572e-01],\n",
       "         [4.71772611e-01],\n",
       "         [4.53948647e-01],\n",
       "         [1.52724519e-01],\n",
       "         [2.21467718e-01],\n",
       "         [1.95014086e-02],\n",
       "         [1.11105040e-01]],\n",
       "\n",
       "        [[5.81380233e-09],\n",
       "         [2.60500330e-02],\n",
       "         [1.66847958e-08],\n",
       "         [9.89684388e-02],\n",
       "         [4.99864906e-01],\n",
       "         [4.50949341e-01],\n",
       "         [3.82516414e-01],\n",
       "         [1.29036337e-01],\n",
       "         [1.83768094e-01],\n",
       "         [1.25944829e-02],\n",
       "         [9.68663320e-02]],\n",
       "\n",
       "        [[7.24652205e-09],\n",
       "         [2.89812144e-02],\n",
       "         [1.72170704e-08],\n",
       "         [1.02669150e-01],\n",
       "         [5.35318553e-01],\n",
       "         [4.29487944e-01],\n",
       "         [4.12994266e-01],\n",
       "         [1.39576867e-01],\n",
       "         [1.91963658e-01],\n",
       "         [1.30563863e-02],\n",
       "         [1.04084052e-01]],\n",
       "\n",
       "        [[6.06154105e-09],\n",
       "         [4.28037606e-02],\n",
       "         [2.31000232e-08],\n",
       "         [1.32117063e-01],\n",
       "         [5.78713536e-01],\n",
       "         [4.60009694e-01],\n",
       "         [5.32073081e-01],\n",
       "         [1.96870178e-01],\n",
       "         [2.43010357e-01],\n",
       "         [1.87698063e-02],\n",
       "         [1.75482631e-01]],\n",
       "\n",
       "        [[6.05376371e-09],\n",
       "         [3.68960202e-02],\n",
       "         [2.13197904e-08],\n",
       "         [1.28368676e-01],\n",
       "         [6.27172947e-01],\n",
       "         [4.36633140e-01],\n",
       "         [5.26264966e-01],\n",
       "         [1.94025993e-01],\n",
       "         [2.43150860e-01],\n",
       "         [1.70038119e-02],\n",
       "         [1.67414486e-01]],\n",
       "\n",
       "        [[1.08545919e-08],\n",
       "         [4.05925028e-02],\n",
       "         [1.91197547e-08],\n",
       "         [1.09047189e-01],\n",
       "         [5.68330526e-01],\n",
       "         [3.95149767e-01],\n",
       "         [4.69213665e-01],\n",
       "         [1.62352383e-01],\n",
       "         [2.05591723e-01],\n",
       "         [1.58412419e-02],\n",
       "         [1.19397290e-01]],\n",
       "\n",
       "        [[1.06866844e-08],\n",
       "         [1.01436771e-01],\n",
       "         [1.97316883e-08],\n",
       "         [1.14744321e-01],\n",
       "         [4.81375158e-01],\n",
       "         [3.61676991e-01],\n",
       "         [4.93533880e-01],\n",
       "         [1.76247209e-01],\n",
       "         [2.22966328e-01],\n",
       "         [2.71484163e-02],\n",
       "         [1.40494898e-01]],\n",
       "\n",
       "        [[1.21875967e-08],\n",
       "         [4.45951000e-02],\n",
       "         [1.97481569e-08],\n",
       "         [1.14193007e-01],\n",
       "         [5.72030365e-01],\n",
       "         [4.00004745e-01],\n",
       "         [4.60895538e-01],\n",
       "         [1.64718658e-01],\n",
       "         [2.12756991e-01],\n",
       "         [1.88877694e-02],\n",
       "         [1.31219164e-01]]],\n",
       "\n",
       "\n",
       "       [[[1.06149072e-08],\n",
       "         [3.04260999e-02],\n",
       "         [1.64421117e-08],\n",
       "         [9.89375487e-02],\n",
       "         [5.27482629e-01],\n",
       "         [4.76772249e-01],\n",
       "         [3.92093986e-01],\n",
       "         [1.31084532e-01],\n",
       "         [2.00299725e-01],\n",
       "         [1.82819255e-02],\n",
       "         [9.46676582e-02]],\n",
       "\n",
       "        [[9.10970233e-09],\n",
       "         [3.89005616e-02],\n",
       "         [1.76130861e-08],\n",
       "         [1.06044851e-01],\n",
       "         [5.01062572e-01],\n",
       "         [4.71772611e-01],\n",
       "         [4.53948647e-01],\n",
       "         [1.52724519e-01],\n",
       "         [2.21467718e-01],\n",
       "         [1.95014086e-02],\n",
       "         [1.11105040e-01]],\n",
       "\n",
       "        [[5.81380233e-09],\n",
       "         [2.60500330e-02],\n",
       "         [1.66847958e-08],\n",
       "         [9.89684388e-02],\n",
       "         [4.99864906e-01],\n",
       "         [4.50949341e-01],\n",
       "         [3.82516414e-01],\n",
       "         [1.29036337e-01],\n",
       "         [1.83768094e-01],\n",
       "         [1.25944829e-02],\n",
       "         [9.68663320e-02]],\n",
       "\n",
       "        [[7.24652205e-09],\n",
       "         [2.89812144e-02],\n",
       "         [1.72170704e-08],\n",
       "         [1.02669150e-01],\n",
       "         [5.35318553e-01],\n",
       "         [4.29487944e-01],\n",
       "         [4.12994266e-01],\n",
       "         [1.39576867e-01],\n",
       "         [1.91963658e-01],\n",
       "         [1.30563863e-02],\n",
       "         [1.04084052e-01]],\n",
       "\n",
       "        [[6.06154105e-09],\n",
       "         [4.28037606e-02],\n",
       "         [2.31000232e-08],\n",
       "         [1.32117063e-01],\n",
       "         [5.78713536e-01],\n",
       "         [4.60009694e-01],\n",
       "         [5.32073081e-01],\n",
       "         [1.96870178e-01],\n",
       "         [2.43010357e-01],\n",
       "         [1.87698063e-02],\n",
       "         [1.75482631e-01]],\n",
       "\n",
       "        [[6.05376371e-09],\n",
       "         [3.68960202e-02],\n",
       "         [2.13197904e-08],\n",
       "         [1.28368676e-01],\n",
       "         [6.27172947e-01],\n",
       "         [4.36633140e-01],\n",
       "         [5.26264966e-01],\n",
       "         [1.94025993e-01],\n",
       "         [2.43150860e-01],\n",
       "         [1.70038119e-02],\n",
       "         [1.67414486e-01]],\n",
       "\n",
       "        [[1.08545919e-08],\n",
       "         [4.05925028e-02],\n",
       "         [1.91197547e-08],\n",
       "         [1.09047189e-01],\n",
       "         [5.68330526e-01],\n",
       "         [3.95149767e-01],\n",
       "         [4.69213665e-01],\n",
       "         [1.62352383e-01],\n",
       "         [2.05591723e-01],\n",
       "         [1.58412419e-02],\n",
       "         [1.19397290e-01]],\n",
       "\n",
       "        [[1.06866844e-08],\n",
       "         [1.01436771e-01],\n",
       "         [1.97316883e-08],\n",
       "         [1.14744321e-01],\n",
       "         [4.81375158e-01],\n",
       "         [3.61676991e-01],\n",
       "         [4.93533880e-01],\n",
       "         [1.76247209e-01],\n",
       "         [2.22966328e-01],\n",
       "         [2.71484163e-02],\n",
       "         [1.40494898e-01]],\n",
       "\n",
       "        [[1.21875967e-08],\n",
       "         [4.45951000e-02],\n",
       "         [1.97481569e-08],\n",
       "         [1.14193007e-01],\n",
       "         [5.72030365e-01],\n",
       "         [4.00004745e-01],\n",
       "         [4.60895538e-01],\n",
       "         [1.64718658e-01],\n",
       "         [2.12756991e-01],\n",
       "         [1.88877694e-02],\n",
       "         [1.31219164e-01]],\n",
       "\n",
       "        [[9.16101239e-09],\n",
       "         [3.37851271e-02],\n",
       "         [1.79160082e-08],\n",
       "         [1.05543904e-01],\n",
       "         [5.76015115e-01],\n",
       "         [4.45875734e-01],\n",
       "         [4.27184075e-01],\n",
       "         [1.45816624e-01],\n",
       "         [1.92431986e-01],\n",
       "         [1.44237261e-02],\n",
       "         [1.13276407e-01]]]])"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d4f55",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "2949d425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19243199, 0.1055439 , 0.03378513, 0.11327641, 0.01442373],\n",
       "       [0.17313728, 0.10107498, 0.02521631, 0.10141373, 0.01119418]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "bf7bb251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5504, 1368)"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a83357",
   "metadata": {},
   "source": [
    "### Define the input dimensions for the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "e1486173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_dims(X_train, exogenous_data_train): \n",
    "    #计算模型输入的维度，X_train: 训练集的主输入数据（通常是一个多维数组）；exogenous_data_train: 训练集的外生数据（可以是 None 或包含外生特征的字典）。\n",
    "    if args.model_name == \"mlp\":\n",
    "        input_dim = X_train.shape[1] * X_train.shape[2] #如果模型是多层感知机（MLP），则将输入的所有特征展平成一个一维向量，因此输入维度是 X_train 的第二维度和第三维度的乘积（即 X_train.shape[1] * X_train.shape[2]）\n",
    "    else:\n",
    "        input_dim = X_train.shape[2] #对于其他模型（如卷积神经网络或循环神经网络），输入维度保持为 X_train 的第三维度（即 X_train.shape[2]）\n",
    "    #计算外生数据的维度\n",
    "    if exogenous_data_train is not None: #如果 exogenous_data_train 不为 None\n",
    "        if len(exogenous_data_train) == 1: #如果外生数据中只有一个区域\n",
    "            cid = next(iter(exogenous_data_train.keys()))\n",
    "            exogenous_dim = exogenous_data_train[cid].shape[1] #从字典中获取该区域的维度。\n",
    "        else:\n",
    "            exogenous_dim = exogenous_data_train[\"all\"].shape[1] #如果外生数据中有多个区域，则使用键为 \"all\" 的区域的维度\n",
    "    else:\n",
    "        exogenous_dim = 0 #如果 exogenous_data_train 为 None，则外生数据的维度为 0\n",
    "    \n",
    "    return input_dim, exogenous_dim #input_dim: 主输入数据的维度；exogenous_dim: 外生数据的维度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6783ff",
   "metadata": {},
   "source": [
    "### Initialize the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "5e7044d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model: str,\n",
    "              input_dim: int,\n",
    "              out_dim: int,\n",
    "              lags: int = 10,\n",
    "              exogenous_dim: int = 0,\n",
    "              seed=0):\n",
    "    if model == \"mlp\":\n",
    "        model = MLP(input_dim=input_dim, layer_units=[256, 128, 64], num_outputs=out_dim)\n",
    "    elif model == \"rnn\":\n",
    "        model = RNN(input_dim=input_dim, rnn_hidden_size=128, num_rnn_layers=1, rnn_dropout=0.0,\n",
    "                    layer_units=[128], num_outputs=out_dim, matrix_rep=True, exogenous_dim=exogenous_dim)\n",
    "    elif model == \"lstm\":\n",
    "        model = LSTM(input_dim=input_dim, lstm_hidden_size=128, num_lstm_layers=1, lstm_dropout=0.0,\n",
    "                     layer_units=[128], num_outputs=out_dim, matrix_rep=True, exogenous_dim=exogenous_dim)\n",
    "    elif model == \"gru\":\n",
    "        model = GRU(input_dim=input_dim, gru_hidden_size=128, num_gru_layers=1, gru_dropout=0.0,\n",
    "                    layer_units=[128], num_outputs=out_dim, matrix_rep=True, exogenous_dim=exogenous_dim)\n",
    "    elif model == \"cnn\":\n",
    "        model = CNN(num_features=input_dim, lags=lags, exogenous_dim=exogenous_dim, out_dim=out_dim)\n",
    "    elif model == \"da_encoder_decoder\":\n",
    "        model = DualAttentionAutoEncoder(input_dim=input_dim, architecture=\"lstm\", matrix_rep=True)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Specified model is not implemented. Plese define your own model or choose one from ['mlp', 'rnn', 'lstm', 'gru', 'cnn', 'da_encoder_decoder']\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "44ed1dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 0\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "args.model_name = \"mlp\"\n",
    "\n",
    "input_dim, exogenous_dim = get_input_dims(X_train, exogenous_data_train)\n",
    "\n",
    "print(input_dim, exogenous_dim)\n",
    "\n",
    "model = get_model(model=args.model_name,\n",
    "                  input_dim=input_dim,\n",
    "                  out_dim=y_train.shape[1],\n",
    "                  lags=args.num_lags,\n",
    "                  exogenous_dim=exogenous_dim,\n",
    "                  seed=args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "8f285c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (MLP_layers): Sequential(\n",
       "    (0): Linear(in_features=110, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=64, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2473d72",
   "metadata": {},
   "source": [
    "### The fit function used to train the model specified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "6b11fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, X_train, y_train, X_val, y_val, #model: 需要训练的模型；X_train, y_train: 训练数据和标签；X_val, y_val: 验证数据和标签\n",
    "        exogenous_data_train=None, exogenous_data_val=None, #exogenous_data_train, exogenous_data_val: 训练和验证数据的外生特征\n",
    "        idxs=[8, 3, 1, 10, 9], # the indices of our targets in X ；idxs: 目标变量在输入数据中的索引\n",
    "        log_per=1): #log_per: 记录训练日志的频率\n",
    "    \n",
    "    # get exogenous data (if any)\n",
    "    if exogenous_data_train is not None and len(exogenous_data_train) > 1:\n",
    "        exogenous_data_train = exogenous_data_train[\"all\"]\n",
    "        exogenous_data_val = exogenous_data_val[\"all\"]\n",
    "    elif exogenous_data_train is not None and len(exogenous_data_train) == 1:\n",
    "        cid = next(iter(exogenous_data_train.keys()))\n",
    "        exogenous_data_train = exogenous_data_train[cid]\n",
    "        exogenous_data_val = exogenous_data_val[cid]\n",
    "    else:\n",
    "        exogenous_data_train = None\n",
    "        exogenous_data_val = None\n",
    "    num_features = len(X_train[0][0]) #计算特征数量，X_train 是一个 3D 数组，形状为 (num_samples, num_lags, num_features)\n",
    "    \n",
    "    # to torch loader\n",
    "    train_loader = to_torch_dataset(X_train, y_train,\n",
    "                                    num_lags=args.num_lags,\n",
    "                                    num_features=num_features,\n",
    "                                    exogenous_data=exogenous_data_train,\n",
    "                                    indices=idxs,\n",
    "                                    batch_size=args.batch_size, \n",
    "                                    shuffle=False)\n",
    "    val_loader = to_torch_dataset(X_val, y_val, \n",
    "                                  num_lags=args.num_lags,\n",
    "                                  num_features=num_features,\n",
    "                                  exogenous_data=exogenous_data_val,\n",
    "                                  indices=idxs,\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  shuffle=False)\n",
    "    \n",
    "    # train the model\n",
    "    model = train(model, \n",
    "                  train_loader, val_loader,\n",
    "                  epochs=args.epochs,\n",
    "                  optimizer=args.optimizer, lr=args.lr,\n",
    "                  criterion=args.criterion,\n",
    "                  early_stopping=args.early_stopping,\n",
    "                  patience=args.patience,\n",
    "                  plot_history=args.plot_history, \n",
    "                  device=device, log_per=log_per)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "681cc512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO logger 2024-05-23 16:58:32,012 | train_utils.py:103 | Epoch 1 [Train]: loss 0.011130027884043324, mse: 0.006565061863511801, rmse: 0.08102506935209498, mae 0.06446090340614319, r2: -0.9310417009027339, nrmse: 3.5501599677534847\n",
      "INFO logger 2024-05-23 16:58:32,012 | train_utils.py:105 | Epoch 1 [Test]: loss 4.700729412391608e-05, mse: 0.00573458056896925, rmse: 0.07572701346923204, mae 0.06321828067302704, r2: -3194.345268166287, nrmse: 38.788018304435994\n",
      "INFO logger 2024-05-23 16:58:32,012 | helpers.py:148 | Validation loss decreased (inf --> 0.000047). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:32,115 | train_utils.py:103 | Epoch 2 [Train]: loss 0.003760452933081894, mse: 0.003090707352384925, rmse: 0.0555941305569655, mae 0.03789808601140976, r2: -0.03257373853291066, nrmse: 2.7394794260928608\n",
      "INFO logger 2024-05-23 16:58:32,115 | train_utils.py:105 | Epoch 2 [Test]: loss 2.0606662585857538e-05, mse: 0.002571853343397379, rmse: 0.05071344341885472, mae 0.03754692152142525, r2: -980.2208244158508, nrmse: 25.6129003757005\n",
      "INFO logger 2024-05-23 16:58:32,116 | helpers.py:148 | Validation loss decreased (0.000047 --> 0.000021). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:32,306 | train_utils.py:103 | Epoch 3 [Train]: loss 0.0032061361232906143, mse: 0.0031994879245758057, rmse: 0.05656401616377506, mae 0.03963562846183777, r2: 0.381561750898438, nrmse: 1.7172303803631206\n",
      "INFO logger 2024-05-23 16:58:32,307 | train_utils.py:105 | Epoch 3 [Test]: loss 1.909124570672689e-05, mse: 0.0023958925157785416, rmse: 0.04894785506821051, mae 0.037457287311553955, r2: -855.9007905389386, nrmse: 21.368221412898777\n",
      "INFO logger 2024-05-23 16:58:32,307 | helpers.py:148 | Validation loss decreased (0.000021 --> 0.000019). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:32,412 | train_utils.py:103 | Epoch 4 [Train]: loss 0.002850044636277236, mse: 0.002693208632990718, rmse: 0.05189613312175309, mae 0.03379940614104271, r2: 0.5793635091527749, nrmse: 1.289648366894095\n",
      "INFO logger 2024-05-23 16:58:32,412 | train_utils.py:105 | Epoch 4 [Test]: loss 1.5631808347221225e-05, mse: 0.0019711556378751993, rmse: 0.044397698565074285, mae 0.030886417254805565, r2: -189.70676114728704, nrmse: 7.253775961263043\n",
      "INFO logger 2024-05-23 16:58:32,413 | helpers.py:148 | Validation loss decreased (0.000019 --> 0.000016). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:32,519 | train_utils.py:103 | Epoch 5 [Train]: loss 0.0025558920276844855, mse: 0.002086665015667677, rmse: 0.045680028630328995, mae 0.028401803225278854, r2: 0.6470459138327964, nrmse: 1.2555380341513718\n",
      "INFO logger 2024-05-23 16:58:32,519 | train_utils.py:105 | Epoch 5 [Test]: loss 1.55669935636511e-05, mse: 0.001966157928109169, rmse: 0.04434137941143881, mae 0.0299379825592041, r2: -195.09060596020885, nrmse: 10.135564094575573\n",
      "INFO logger 2024-05-23 16:58:32,519 | helpers.py:148 | Validation loss decreased (0.000016 --> 0.000016). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:32,632 | train_utils.py:103 | Epoch 6 [Train]: loss 0.0022810976855442617, mse: 0.0022192802280187607, rmse: 0.04710923718357962, mae 0.030728721991181374, r2: 0.5192647723868874, nrmse: 1.6307906099203588\n",
      "INFO logger 2024-05-23 16:58:32,632 | train_utils.py:105 | Epoch 6 [Test]: loss 1.4659284279757991e-05, mse: 0.001850676373578608, rmse: 0.043019488299823, mae 0.028363928198814392, r2: -138.29368828249264, nrmse: 8.540886072710805\n",
      "INFO logger 2024-05-23 16:58:32,632 | helpers.py:148 | Validation loss decreased (0.000016 --> 0.000015). Caching model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO logger 2024-05-23 16:58:32,741 | train_utils.py:103 | Epoch 7 [Train]: loss 0.0022481655487248393, mse: 0.0023429328575730324, rmse: 0.04840385168117339, mae 0.0317036397755146, r2: 0.5484767028965292, nrmse: 1.5117997821582883\n",
      "INFO logger 2024-05-23 16:58:32,741 | train_utils.py:105 | Epoch 7 [Test]: loss 1.4560868315485835e-05, mse: 0.0018366407603025436, rmse: 0.042856046951422665, mae 0.027722066268324852, r2: -105.28509861635764, nrmse: 7.823383412779401\n",
      "INFO logger 2024-05-23 16:58:32,741 | helpers.py:148 | Validation loss decreased (0.000015 --> 0.000015). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:32,846 | train_utils.py:103 | Epoch 8 [Train]: loss 0.0022377225839929535, mse: 0.0019373869290575385, rmse: 0.044015757735810235, mae 0.027366673573851585, r2: 0.6787241211551985, nrmse: 1.187368269664122\n",
      "INFO logger 2024-05-23 16:58:32,846 | train_utils.py:105 | Epoch 8 [Test]: loss 1.4576601318617443e-05, mse: 0.001834755763411522, rmse: 0.04283404911296061, mae 0.02839132770895958, r2: -87.6031749212543, nrmse: 6.886685742662842\n",
      "INFO logger 2024-05-23 16:58:32,846 | helpers.py:136 | EarlyStopping counter: 1 out of 50\n",
      "INFO logger 2024-05-23 16:58:32,949 | train_utils.py:103 | Epoch 9 [Train]: loss 0.0019694497917963987, mse: 0.00184535956941545, rmse: 0.04295764855547205, mae 0.025782084092497826, r2: 0.6763113828377894, nrmse: 1.2361872178960904\n",
      "INFO logger 2024-05-23 16:58:32,949 | train_utils.py:105 | Epoch 9 [Test]: loss 1.3828958421795798e-05, mse: 0.001748606562614441, rmse: 0.04181634324775949, mae 0.026057954877614975, r2: -60.87310054901354, nrmse: 5.672370553475676\n",
      "INFO logger 2024-05-23 16:58:32,950 | helpers.py:148 | Validation loss decreased (0.000015 --> 0.000014). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:33,055 | train_utils.py:103 | Epoch 10 [Train]: loss 0.0018378650869117549, mse: 0.001789364730939269, rmse: 0.042300883335212626, mae 0.024756092578172684, r2: 0.7091126699766855, nrmse: 1.1224666574334101\n",
      "INFO logger 2024-05-23 16:58:33,055 | train_utils.py:105 | Epoch 10 [Test]: loss 1.331399703277166e-05, mse: 0.0016824646154418588, rmse: 0.04101785727511688, mae 0.02545619010925293, r2: -52.02927871791552, nrmse: 5.58040012643629\n",
      "INFO logger 2024-05-23 16:58:33,055 | helpers.py:148 | Validation loss decreased (0.000014 --> 0.000013). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:33,236 | train_utils.py:103 | Epoch 11 [Train]: loss 0.0018844485533347408, mse: 0.001856599235907197, rmse: 0.043088272602962364, mae 0.026689007878303528, r2: 0.646591291485019, nrmse: 1.3323174325143605\n",
      "INFO logger 2024-05-23 16:58:33,237 | train_utils.py:105 | Epoch 11 [Test]: loss 1.3317810272803389e-05, mse: 0.00168140628375113, rmse: 0.041004954380551746, mae 0.026331547647714615, r2: -57.19408722569976, nrmse: 5.386693924163608\n",
      "INFO logger 2024-05-23 16:58:33,237 | helpers.py:136 | EarlyStopping counter: 1 out of 50\n",
      "INFO logger 2024-05-23 16:58:33,341 | train_utils.py:103 | Epoch 12 [Train]: loss 0.0018093704750775264, mse: 0.0018752862233668566, rmse: 0.04330457508585965, mae 0.025813594460487366, r2: 0.7108487563303492, nrmse: 1.0760863570620829\n",
      "INFO logger 2024-05-23 16:58:33,341 | train_utils.py:105 | Epoch 12 [Test]: loss 1.4727335247586956e-05, mse: 0.001863289624452591, rmse: 0.04316583862793113, mae 0.02667953632771969, r2: -47.08186005301907, nrmse: 5.2872587672126885\n",
      "INFO logger 2024-05-23 16:58:33,341 | helpers.py:136 | EarlyStopping counter: 2 out of 50\n",
      "INFO logger 2024-05-23 16:58:33,445 | train_utils.py:103 | Epoch 13 [Train]: loss 0.002264858775592878, mse: 0.001995387487113476, rmse: 0.04466976032075252, mae 0.027421826496720314, r2: 0.6996684123800613, nrmse: 1.1566266278250337\n",
      "INFO logger 2024-05-23 16:58:33,446 | train_utils.py:105 | Epoch 13 [Test]: loss 1.3156707253244472e-05, mse: 0.0016651289770379663, rmse: 0.040805991925671484, mae 0.02633001282811165, r2: -97.24877013193687, nrmse: 7.354733234673864\n",
      "INFO logger 2024-05-23 16:58:33,446 | helpers.py:148 | Validation loss decreased (0.000013 --> 0.000013). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:33,553 | train_utils.py:103 | Epoch 14 [Train]: loss 0.002047587637926606, mse: 0.0017822416266426444, rmse: 0.04221660368436386, mae 0.025386691093444824, r2: 0.7195063547885434, nrmse: 1.063058582562541\n",
      "INFO logger 2024-05-23 16:58:33,553 | train_utils.py:105 | Epoch 14 [Test]: loss 1.418590052080564e-05, mse: 0.001784564577974379, rmse: 0.04224410702067661, mae 0.027517294511198997, r2: -36.28445390176933, nrmse: 4.5478010361828725\n",
      "INFO logger 2024-05-23 16:58:33,553 | helpers.py:136 | EarlyStopping counter: 1 out of 50\n",
      "INFO logger 2024-05-23 16:58:33,661 | train_utils.py:103 | Epoch 15 [Train]: loss 0.0018810292680491118, mse: 0.0017595303943380713, rmse: 0.04194675666053421, mae 0.02432629093527794, r2: 0.7308871505199438, nrmse: 1.0868445113438276\n",
      "INFO logger 2024-05-23 16:58:33,662 | train_utils.py:105 | Epoch 15 [Test]: loss 1.2997602420138762e-05, mse: 0.0016447845846414566, rmse: 0.040555943887936534, mae 0.025314638391137123, r2: -65.16263431647552, nrmse: 6.400806094623811\n",
      "INFO logger 2024-05-23 16:58:33,662 | helpers.py:148 | Validation loss decreased (0.000013 --> 0.000013). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:33,776 | train_utils.py:103 | Epoch 16 [Train]: loss 0.0018092720837832826, mse: 0.0017415909096598625, rmse: 0.04173237244226432, mae 0.025067728012800217, r2: 0.7323998008651239, nrmse: 1.0744848128374034\n",
      "INFO logger 2024-05-23 16:58:33,776 | train_utils.py:105 | Epoch 16 [Test]: loss 1.3152564595295497e-05, mse: 0.0016613289481028914, rmse: 0.04075940318629422, mae 0.02584961988031864, r2: -52.81593426836969, nrmse: 5.714056257696137\n",
      "INFO logger 2024-05-23 16:58:33,777 | helpers.py:136 | EarlyStopping counter: 1 out of 50\n",
      "INFO logger 2024-05-23 16:58:33,893 | train_utils.py:103 | Epoch 17 [Train]: loss 0.0018345009029951333, mse: 0.0017372429138049483, rmse: 0.0416802460861851, mae 0.024339482188224792, r2: 0.729745964449088, nrmse: 1.1012181616521215\n",
      "INFO logger 2024-05-23 16:58:33,893 | train_utils.py:105 | Epoch 17 [Test]: loss 1.2929567280708818e-05, mse: 0.001636468805372715, rmse: 0.04045329165065205, mae 0.024563321843743324, r2: -35.80923055626041, nrmse: 4.468896398495905\n",
      "INFO logger 2024-05-23 16:58:33,893 | helpers.py:148 | Validation loss decreased (0.000013 --> 0.000013). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:34,011 | train_utils.py:103 | Epoch 18 [Train]: loss 0.0017697758374641463, mse: 0.001697250409051776, rmse: 0.04119769907472717, mae 0.024318542331457138, r2: 0.7353368212343971, nrmse: 1.080236144801431\n",
      "INFO logger 2024-05-23 16:58:34,012 | train_utils.py:105 | Epoch 18 [Test]: loss 1.2832561299158533e-05, mse: 0.0016225877916440368, rmse: 0.040281357867430895, mae 0.024707498028874397, r2: -34.390393066805, nrmse: 4.661271302767258\n",
      "INFO logger 2024-05-23 16:58:34,012 | helpers.py:148 | Validation loss decreased (0.000013 --> 0.000013). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:34,129 | train_utils.py:103 | Epoch 19 [Train]: loss 0.0017512483837774282, mse: 0.0017452423926442862, rmse: 0.041776098341567106, mae 0.024904990568757057, r2: 0.7282173980222708, nrmse: 1.1104107774454952\n",
      "INFO logger 2024-05-23 16:58:34,130 | train_utils.py:105 | Epoch 19 [Test]: loss 1.2634258052846144e-05, mse: 0.001597756752744317, rmse: 0.03997194957397396, mae 0.02446633391082287, r2: -34.55438122916909, nrmse: 4.6809588406248155\n",
      "INFO logger 2024-05-23 16:58:34,130 | helpers.py:148 | Validation loss decreased (0.000013 --> 0.000013). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:34,247 | train_utils.py:103 | Epoch 20 [Train]: loss 0.001769074147802691, mse: 0.0017239153385162354, rmse: 0.04152005947149203, mae 0.025036657229065895, r2: 0.7335598834420819, nrmse: 1.0867223126647512\n",
      "INFO logger 2024-05-23 16:58:34,247 | train_utils.py:105 | Epoch 20 [Test]: loss 1.2825149906614022e-05, mse: 0.001621214672923088, rmse: 0.04026431016325858, mae 0.024740654975175858, r2: -28.307038595806155, nrmse: 4.03680126781047\n",
      "INFO logger 2024-05-23 16:58:34,248 | helpers.py:136 | EarlyStopping counter: 1 out of 50\n",
      "INFO logger 2024-05-23 16:58:34,440 | train_utils.py:103 | Epoch 21 [Train]: loss 0.0018137389286197883, mse: 0.001789834932424128, rmse: 0.04230644079125693, mae 0.02529144287109375, r2: 0.720391541040898, nrmse: 1.1410604206576598\n",
      "INFO logger 2024-05-23 16:58:34,441 | train_utils.py:105 | Epoch 21 [Test]: loss 1.26932935134987e-05, mse: 0.0016056473832577467, rmse: 0.04007053010951748, mae 0.024420179426670074, r2: -35.062327363833305, nrmse: 4.740980544784832\n",
      "INFO logger 2024-05-23 16:58:34,441 | helpers.py:136 | EarlyStopping counter: 2 out of 50\n",
      "INFO logger 2024-05-23 16:58:34,559 | train_utils.py:103 | Epoch 22 [Train]: loss 0.001834726946188227, mse: 0.0016584191471338272, rmse: 0.040723692700120245, mae 0.023956971243023872, r2: 0.749667601165559, nrmse: 1.0355600006163985\n",
      "INFO logger 2024-05-23 16:58:34,559 | train_utils.py:105 | Epoch 22 [Test]: loss 1.2848218564251819e-05, mse: 0.0016207859152927995, rmse: 0.040258985522399836, mae 0.024946315214037895, r2: -23.474875362834982, nrmse: 3.708919623425014\n",
      "INFO logger 2024-05-23 16:58:34,559 | helpers.py:136 | EarlyStopping counter: 3 out of 50\n",
      "INFO logger 2024-05-23 16:58:34,675 | train_utils.py:103 | Epoch 23 [Train]: loss 0.0017583524793756855, mse: 0.0016253432258963585, rmse: 0.04031554571001562, mae 0.023339558392763138, r2: 0.742147564903291, nrmse: 1.0866637367895322\n",
      "INFO logger 2024-05-23 16:58:34,676 | train_utils.py:105 | Epoch 23 [Test]: loss 1.2750779961069709e-05, mse: 0.0016130029689520597, rmse: 0.040162208218075604, mae 0.02431502565741539, r2: -26.4640800549633, nrmse: 4.0845595672293795\n",
      "INFO logger 2024-05-23 16:58:34,676 | helpers.py:136 | EarlyStopping counter: 4 out of 50\n",
      "INFO logger 2024-05-23 16:58:34,791 | train_utils.py:103 | Epoch 24 [Train]: loss 0.0016943619738264905, mse: 0.0016224043210968375, rmse: 0.040279080440060164, mae 0.02375825308263302, r2: 0.7446888824270502, nrmse: 1.072522166228897\n",
      "INFO logger 2024-05-23 16:58:34,792 | train_utils.py:105 | Epoch 24 [Test]: loss 1.2637424541089945e-05, mse: 0.0015983335906639695, rmse: 0.039979164456801365, mae 0.02447478473186493, r2: -25.923224576117356, nrmse: 3.7502498551870267\n",
      "INFO logger 2024-05-23 16:58:34,792 | helpers.py:136 | EarlyStopping counter: 5 out of 50\n",
      "INFO logger 2024-05-23 16:58:34,909 | train_utils.py:103 | Epoch 25 [Train]: loss 0.0016971627487903387, mse: 0.0016592539614066482, rmse: 0.040733941147483486, mae 0.024388447403907776, r2: 0.7329899560524128, nrmse: 1.1202284351219742\n",
      "INFO logger 2024-05-23 16:58:34,910 | train_utils.py:105 | Epoch 25 [Test]: loss 1.2616268992260621e-05, mse: 0.001594926230609417, rmse: 0.039936527523176286, mae 0.024533383548259735, r2: -32.5195705364024, nrmse: 4.581163013515478\n",
      "INFO logger 2024-05-23 16:58:34,910 | helpers.py:148 | Validation loss decreased (0.000013 --> 0.000013). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:35,031 | train_utils.py:103 | Epoch 26 [Train]: loss 0.0017024407615714831, mse: 0.0016464038053527474, rmse: 0.04057590178114034, mae 0.02410798706114292, r2: 0.7437689502565556, nrmse: 1.079516684430343\n",
      "INFO logger 2024-05-23 16:58:35,031 | train_utils.py:105 | Epoch 26 [Test]: loss 1.286777221102115e-05, mse: 0.001628114259801805, rmse: 0.04034989789084732, mae 0.024491582065820694, r2: -23.782247058331222, nrmse: 3.7306993098993733\n",
      "INFO logger 2024-05-23 16:58:35,031 | helpers.py:136 | EarlyStopping counter: 1 out of 50\n",
      "INFO logger 2024-05-23 16:58:35,147 | train_utils.py:103 | Epoch 27 [Train]: loss 0.0017388432312716675, mse: 0.0018025016179308295, rmse: 0.042455878484973425, mae 0.02486759051680565, r2: 0.7351590966658511, nrmse: 1.0745699027580091\n",
      "INFO logger 2024-05-23 16:58:35,148 | train_utils.py:105 | Epoch 27 [Test]: loss 1.2537334085379494e-05, mse: 0.001586921513080597, rmse: 0.039836183465294425, mae 0.023917540907859802, r2: -25.437925257440412, nrmse: 3.9958560160393084\n",
      "INFO logger 2024-05-23 16:58:35,148 | helpers.py:148 | Validation loss decreased (0.000013 --> 0.000013). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:35,265 | train_utils.py:103 | Epoch 28 [Train]: loss 0.001974172585272923, mse: 0.0017702383920550346, rmse: 0.042074201026936146, mae 0.025923585519194603, r2: 0.7368271431600233, nrmse: 1.042005046876205\n",
      "INFO logger 2024-05-23 16:58:35,265 | train_utils.py:105 | Epoch 28 [Test]: loss 1.4026061688244822e-05, mse: 0.00176061294041574, rmse: 0.04195965848783496, mae 0.026987504214048386, r2: -25.801111413279777, nrmse: 3.9698360996848923\n",
      "INFO logger 2024-05-23 16:58:35,265 | helpers.py:136 | EarlyStopping counter: 1 out of 50\n",
      "INFO logger 2024-05-23 16:58:35,381 | train_utils.py:103 | Epoch 29 [Train]: loss 0.0018886105821958302, mse: 0.0017184127354994416, rmse: 0.04145374211696022, mae 0.02564128302037716, r2: 0.6749583086494761, nrmse: 1.2973992953779736\n",
      "INFO logger 2024-05-23 16:58:35,381 | train_utils.py:105 | Epoch 29 [Test]: loss 1.4071574377451549e-05, mse: 0.0017793200677260756, rmse: 0.04218198747956378, mae 0.02977190539240837, r2: -260.30396103668943, nrmse: 12.604508721408603\n",
      "INFO logger 2024-05-23 16:58:35,382 | helpers.py:136 | EarlyStopping counter: 2 out of 50\n",
      "INFO logger 2024-05-23 16:58:35,574 | train_utils.py:103 | Epoch 30 [Train]: loss 0.001704297252059024, mse: 0.0015800815308466554, rmse: 0.03975023938099814, mae 0.023057473823428154, r2: 0.7552801306196173, nrmse: 1.0247202534275683\n",
      "INFO logger 2024-05-23 16:58:35,574 | train_utils.py:105 | Epoch 30 [Test]: loss 1.2694908648440668e-05, mse: 0.0016031734412536025, rmse: 0.04003964836575869, mae 0.024950221180915833, r2: -24.46469432060314, nrmse: 3.7826998459370147\n",
      "INFO logger 2024-05-23 16:58:35,575 | helpers.py:136 | EarlyStopping counter: 3 out of 50\n",
      "INFO logger 2024-05-23 16:58:35,692 | train_utils.py:103 | Epoch 31 [Train]: loss 0.001718993959947733, mse: 0.0015814481303095818, rmse: 0.03976742549260112, mae 0.023759180679917336, r2: 0.7438377629441191, nrmse: 1.0990414482878332\n",
      "INFO logger 2024-05-23 16:58:35,692 | train_utils.py:105 | Epoch 31 [Test]: loss 1.2701046365457559e-05, mse: 0.0016040591290220618, rmse: 0.04005070697281213, mae 0.025474151596426964, r2: -45.42692270145863, nrmse: 5.081489665167487\n",
      "INFO logger 2024-05-23 16:58:35,693 | helpers.py:136 | EarlyStopping counter: 4 out of 50\n",
      "INFO logger 2024-05-23 16:58:35,809 | train_utils.py:103 | Epoch 32 [Train]: loss 0.0016849357402650132, mse: 0.0015547072980552912, rmse: 0.039429776794388416, mae 0.023156609386205673, r2: 0.7630176781697651, nrmse: 1.0152250436074661\n",
      "INFO logger 2024-05-23 16:58:35,810 | train_utils.py:105 | Epoch 32 [Test]: loss 1.2676577575297819e-05, mse: 0.001601373078301549, rmse: 0.040017159798036, mae 0.025187188759446144, r2: -32.15286258978796, nrmse: 3.8156223744024063\n",
      "INFO logger 2024-05-23 16:58:35,810 | helpers.py:136 | EarlyStopping counter: 5 out of 50\n",
      "INFO logger 2024-05-23 16:58:35,926 | train_utils.py:103 | Epoch 33 [Train]: loss 0.0017038918149938941, mse: 0.0016249259933829308, rmse: 0.04031037079193059, mae 0.02429104968905449, r2: 0.74568389643647, nrmse: 1.0670808184812044\n",
      "INFO logger 2024-05-23 16:58:35,926 | train_utils.py:105 | Epoch 33 [Test]: loss 1.2833782596301222e-05, mse: 0.0016241244738921523, rmse: 0.04030042771351382, mae 0.024521751329302788, r2: -26.8646100779584, nrmse: 3.913105357904159\n",
      "INFO logger 2024-05-23 16:58:35,926 | helpers.py:136 | EarlyStopping counter: 6 out of 50\n",
      "INFO logger 2024-05-23 16:58:36,043 | train_utils.py:103 | Epoch 34 [Train]: loss 0.0017673075496087794, mse: 0.0016743395244702697, rmse: 0.04091869407092887, mae 0.02534596621990204, r2: 0.7414681918506469, nrmse: 1.0665239327717773\n",
      "INFO logger 2024-05-23 16:58:36,044 | train_utils.py:105 | Epoch 34 [Test]: loss 1.2774357765542658e-05, mse: 0.0016127629205584526, rmse: 0.04015921962088472, mae 0.026095103472471237, r2: -49.818231905089306, nrmse: 4.363139301248372\n",
      "INFO logger 2024-05-23 16:58:36,044 | helpers.py:136 | EarlyStopping counter: 7 out of 50\n",
      "INFO logger 2024-05-23 16:58:36,159 | train_utils.py:103 | Epoch 35 [Train]: loss 0.0018482783827155715, mse: 0.0016952862497419119, rmse: 0.04117385395784456, mae 0.026645952835679054, r2: 0.723766757991656, nrmse: 1.1321258956730678\n",
      "INFO logger 2024-05-23 16:58:36,160 | train_utils.py:105 | Epoch 35 [Test]: loss 1.3568537134121647e-05, mse: 0.0017072984483093023, rmse: 0.04131946815133639, mae 0.028049122542142868, r2: -73.3069815861622, nrmse: 5.922465420691693\n",
      "INFO logger 2024-05-23 16:58:36,160 | helpers.py:136 | EarlyStopping counter: 8 out of 50\n",
      "INFO logger 2024-05-23 16:58:36,276 | train_utils.py:103 | Epoch 36 [Train]: loss 0.00178760645322591, mse: 0.0016235020011663437, rmse: 0.04029270406868151, mae 0.025067484006285667, r2: 0.7414251636421821, nrmse: 1.0850069383716214\n",
      "INFO logger 2024-05-23 16:58:36,276 | train_utils.py:105 | Epoch 36 [Test]: loss 1.3248509286946416e-05, mse: 0.001669940771535039, rmse: 0.04086490880370393, mae 0.027017205953598022, r2: -51.27151259791515, nrmse: 4.537826561496835\n",
      "INFO logger 2024-05-23 16:58:36,276 | helpers.py:136 | EarlyStopping counter: 9 out of 50\n",
      "INFO logger 2024-05-23 16:58:36,398 | train_utils.py:103 | Epoch 37 [Train]: loss 0.0017267921068492417, mse: 0.0016147373244166374, rmse: 0.04018379430089495, mae 0.02422315999865532, r2: 0.7506306538907849, nrmse: 1.0494955529768104\n",
      "INFO logger 2024-05-23 16:58:36,398 | train_utils.py:105 | Epoch 37 [Test]: loss 1.3350875798356855e-05, mse: 0.0016803886974230409, rmse: 0.04099254441264949, mae 0.02682507410645485, r2: -44.48817966839225, nrmse: 4.783340289994095\n",
      "INFO logger 2024-05-23 16:58:36,398 | helpers.py:136 | EarlyStopping counter: 10 out of 50\n",
      "INFO logger 2024-05-23 16:58:36,518 | train_utils.py:103 | Epoch 38 [Train]: loss 0.0017368659326927817, mse: 0.0015644619707018137, rmse: 0.0395532801509788, mae 0.02348124235868454, r2: 0.7557944797535199, nrmse: 1.0457484970223294\n",
      "INFO logger 2024-05-23 16:58:36,519 | train_utils.py:105 | Epoch 38 [Test]: loss 1.3111310341117674e-05, mse: 0.0016531867440789938, rmse: 0.040659399209518506, mae 0.026123398914933205, r2: -36.98599118464907, nrmse: 4.3016811394037395\n",
      "INFO logger 2024-05-23 16:58:36,519 | helpers.py:136 | EarlyStopping counter: 11 out of 50\n",
      "INFO logger 2024-05-23 16:58:36,711 | train_utils.py:103 | Epoch 39 [Train]: loss 0.001723086320516602, mse: 0.0016148090362548828, rmse: 0.04018468658898415, mae 0.024929944425821304, r2: 0.7500965021651926, nrmse: 1.0596142676975846\n",
      "INFO logger 2024-05-23 16:58:36,712 | train_utils.py:105 | Epoch 39 [Test]: loss 1.3699907059263853e-05, mse: 0.001722655608318746, rmse: 0.04150488655952147, mae 0.02760554477572441, r2: -52.717441822599845, nrmse: 5.267208145982902\n",
      "INFO logger 2024-05-23 16:58:36,712 | helpers.py:136 | EarlyStopping counter: 12 out of 50\n",
      "INFO logger 2024-05-23 16:58:36,829 | train_utils.py:103 | Epoch 40 [Train]: loss 0.0017412155624655032, mse: 0.0016335087129846215, rmse: 0.0404166885455083, mae 0.024941710755228996, r2: 0.7451837045733646, nrmse: 1.0717374823944055\n",
      "INFO logger 2024-05-23 16:58:36,829 | train_utils.py:105 | Epoch 40 [Test]: loss 1.3739898019982229e-05, mse: 0.0017278592567890882, rmse: 0.04156752646945796, mae 0.027011564001441002, r2: -30.84150744530274, nrmse: 3.8869462923362152\n",
      "INFO logger 2024-05-23 16:58:36,830 | helpers.py:136 | EarlyStopping counter: 13 out of 50\n",
      "INFO logger 2024-05-23 16:58:36,946 | train_utils.py:103 | Epoch 41 [Train]: loss 0.0017150204098153302, mse: 0.0016009907703846693, rmse: 0.04001238271316355, mae 0.02457026019692421, r2: 0.7540923892383203, nrmse: 1.039069786485602\n",
      "INFO logger 2024-05-23 16:58:36,946 | train_utils.py:105 | Epoch 41 [Test]: loss 1.3583655680505266e-05, mse: 0.0017092808848246932, rmse: 0.041343450325592, mae 0.02723448909819126, r2: -39.093823100122584, nrmse: 4.0154901919849255\n",
      "INFO logger 2024-05-23 16:58:36,947 | helpers.py:136 | EarlyStopping counter: 14 out of 50\n",
      "INFO logger 2024-05-23 16:58:37,062 | train_utils.py:103 | Epoch 42 [Train]: loss 0.001690882694780411, mse: 0.001601921976543963, rmse: 0.04002401749629793, mae 0.024379439651966095, r2: 0.7552233508267789, nrmse: 1.037233822360631\n",
      "INFO logger 2024-05-23 16:58:37,063 | train_utils.py:105 | Epoch 42 [Test]: loss 1.3655988315368147e-05, mse: 0.001718358718790114, rmse: 0.04145309058188682, mae 0.027087783440947533, r2: -37.60047445566962, nrmse: 4.558101122478312\n",
      "INFO logger 2024-05-23 16:58:37,063 | helpers.py:136 | EarlyStopping counter: 15 out of 50\n",
      "INFO logger 2024-05-23 16:58:37,180 | train_utils.py:103 | Epoch 43 [Train]: loss 0.0016824106443024459, mse: 0.0016002666670829058, rmse: 0.04000333319965857, mae 0.024737168103456497, r2: 0.7546102976757445, nrmse: 1.029192305273122\n",
      "INFO logger 2024-05-23 16:58:37,180 | train_utils.py:105 | Epoch 43 [Test]: loss 1.3587727195757567e-05, mse: 0.0017096545780077577, rmse: 0.04134796945446968, mae 0.027595262974500656, r2: -48.063370693907274, nrmse: 4.377202698673382\n",
      "INFO logger 2024-05-23 16:58:37,180 | helpers.py:136 | EarlyStopping counter: 16 out of 50\n",
      "INFO logger 2024-05-23 16:58:37,299 | train_utils.py:103 | Epoch 44 [Train]: loss 0.0016668289588482746, mse: 0.0015306773129850626, rmse: 0.03912387139567176, mae 0.023553544655442238, r2: 0.7594325598385026, nrmse: 1.0388682665422355\n",
      "INFO logger 2024-05-23 16:58:37,299 | train_utils.py:105 | Epoch 44 [Test]: loss 1.292481861207961e-05, mse: 0.0016294845845550299, rmse: 0.040366874842561566, mae 0.026198361068964005, r2: -39.35897367776082, nrmse: 4.35581953431014\n",
      "INFO logger 2024-05-23 16:58:37,300 | helpers.py:136 | EarlyStopping counter: 17 out of 50\n",
      "INFO logger 2024-05-23 16:58:37,415 | train_utils.py:103 | Epoch 45 [Train]: loss 0.0016269633874058896, mse: 0.0015648019034415483, rmse: 0.03955757706737798, mae 0.02329936809837818, r2: 0.7626597840363939, nrmse: 1.004186242041364\n",
      "INFO logger 2024-05-23 16:58:37,416 | train_utils.py:105 | Epoch 45 [Test]: loss 1.2876740913791855e-05, mse: 0.0016232568304985762, rmse: 0.04028966158332155, mae 0.025226648896932602, r2: -15.477469472285625, nrmse: 2.9835793074995585\n",
      "INFO logger 2024-05-23 16:58:37,416 | helpers.py:136 | EarlyStopping counter: 18 out of 50\n",
      "INFO logger 2024-05-23 16:58:37,532 | train_utils.py:103 | Epoch 46 [Train]: loss 0.0017027763698701335, mse: 0.0016127924900501966, rmse: 0.04015958777241366, mae 0.024632751941680908, r2: 0.7570324442893654, nrmse: 1.0129085629174246\n",
      "INFO logger 2024-05-23 16:58:37,533 | train_utils.py:105 | Epoch 46 [Test]: loss 1.3690937377855574e-05, mse: 0.0017215462867170572, rmse: 0.041491520660456124, mae 0.02692926488816738, r2: -22.618098920769434, nrmse: 2.9228752218607545\n",
      "INFO logger 2024-05-23 16:58:37,533 | helpers.py:136 | EarlyStopping counter: 19 out of 50\n",
      "INFO logger 2024-05-23 16:58:37,672 | train_utils.py:103 | Epoch 47 [Train]: loss 0.0016949990443441323, mse: 0.0016000674804672599, rmse: 0.04000084349694716, mae 0.0238793957978487, r2: 0.7611291573227523, nrmse: 1.0230034608738667\n",
      "INFO logger 2024-05-23 16:58:37,672 | train_utils.py:105 | Epoch 47 [Test]: loss 1.3476010780966683e-05, mse: 0.001694205799140036, rmse: 0.04116073127557425, mae 0.025768304243683815, r2: -12.887892107088401, nrmse: 2.611130206012017\n",
      "INFO logger 2024-05-23 16:58:37,672 | helpers.py:136 | EarlyStopping counter: 20 out of 50\n",
      "INFO logger 2024-05-23 16:58:37,865 | train_utils.py:103 | Epoch 48 [Train]: loss 0.0016005536725610591, mse: 0.0015695353504270315, rmse: 0.03961736172976479, mae 0.02262250706553459, r2: 0.7676820336461768, nrmse: 0.9937652547919258\n",
      "INFO logger 2024-05-23 16:58:37,866 | train_utils.py:105 | Epoch 48 [Test]: loss 1.3434808011635135e-05, mse: 0.001697996980510652, rmse: 0.04120675891781168, mae 0.025473106652498245, r2: -21.895591797603533, nrmse: 2.918573712671564\n",
      "INFO logger 2024-05-23 16:58:37,866 | helpers.py:136 | EarlyStopping counter: 21 out of 50\n",
      "INFO logger 2024-05-23 16:58:37,988 | train_utils.py:103 | Epoch 49 [Train]: loss 0.0017332253331661313, mse: 0.0015862280270084739, rmse: 0.03982747829085434, mae 0.023341888561844826, r2: 0.7645671713823258, nrmse: 1.002349948003037\n",
      "INFO logger 2024-05-23 16:58:37,988 | train_utils.py:105 | Epoch 49 [Test]: loss 1.260834155986848e-05, mse: 0.0015917442506179214, rmse: 0.03989666966825579, mae 0.02523132786154747, r2: -28.326007741370223, nrmse: 3.538768116701789\n",
      "INFO logger 2024-05-23 16:58:37,988 | helpers.py:136 | EarlyStopping counter: 22 out of 50\n",
      "INFO logger 2024-05-23 16:58:38,109 | train_utils.py:103 | Epoch 50 [Train]: loss 0.0017552332513353808, mse: 0.0016535198083147407, rmse: 0.040663494787275, mae 0.024962913244962692, r2: 0.7292675014346741, nrmse: 1.1334685623728284\n",
      "INFO logger 2024-05-23 16:58:38,109 | train_utils.py:105 | Epoch 50 [Test]: loss 1.2855912655406789e-05, mse: 0.001621633069589734, rmse: 0.04026950545499329, mae 0.025144407525658607, r2: -14.347078676944562, nrmse: 2.6731084555776072\n",
      "INFO logger 2024-05-23 16:58:38,110 | helpers.py:136 | EarlyStopping counter: 23 out of 50\n",
      "INFO logger 2024-05-23 16:58:38,227 | train_utils.py:103 | Epoch 51 [Train]: loss 0.0018428768114465003, mse: 0.001875326270237565, rmse: 0.04330503746953194, mae 0.025438379496335983, r2: 0.7120531670877963, nrmse: 1.1071499490210392\n",
      "INFO logger 2024-05-23 16:58:38,228 | train_utils.py:105 | Epoch 51 [Test]: loss 1.53098642425775e-05, mse: 0.0019199071684852242, rmse: 0.043816745297719506, mae 0.028139492496848106, r2: -15.527572066918271, nrmse: 2.959161464924865\n",
      "INFO logger 2024-05-23 16:58:38,228 | helpers.py:136 | EarlyStopping counter: 24 out of 50\n",
      "INFO logger 2024-05-23 16:58:38,345 | train_utils.py:103 | Epoch 52 [Train]: loss 0.0018133115747839964, mse: 0.0016475582960993052, rmse: 0.040590125598466746, mae 0.024301331490278244, r2: 0.7600145043262712, nrmse: 1.0187306497724709\n",
      "INFO logger 2024-05-23 16:58:38,345 | train_utils.py:105 | Epoch 52 [Test]: loss 1.4030367523371868e-05, mse: 0.0017651859670877457, rmse: 0.042014116283551006, mae 0.026983490213751793, r2: -25.205579640320877, nrmse: 3.7977742679416577\n",
      "INFO logger 2024-05-23 16:58:38,345 | helpers.py:136 | EarlyStopping counter: 25 out of 50\n",
      "INFO logger 2024-05-23 16:58:38,462 | train_utils.py:103 | Epoch 53 [Train]: loss 0.0016729498243495432, mse: 0.0016539255157113075, rmse: 0.040668483076103386, mae 0.024172620847821236, r2: 0.7606385886985361, nrmse: 1.010919307638463\n",
      "INFO logger 2024-05-23 16:58:38,462 | train_utils.py:105 | Epoch 53 [Test]: loss 1.427643913339976e-05, mse: 0.0017944008577615023, rmse: 0.042360368952140896, mae 0.027217676863074303, r2: -24.12691783990859, nrmse: 3.738138042652452\n",
      "INFO logger 2024-05-23 16:58:38,462 | helpers.py:136 | EarlyStopping counter: 26 out of 50\n",
      "INFO logger 2024-05-23 16:58:38,578 | train_utils.py:103 | Epoch 54 [Train]: loss 0.001636132138438095, mse: 0.0016807714710012078, rmse: 0.04099721296626403, mae 0.023984719067811966, r2: 0.743398977638285, nrmse: 1.0306466443716165\n",
      "INFO logger 2024-05-23 16:58:38,578 | train_utils.py:105 | Epoch 54 [Test]: loss 1.3415919668218175e-05, mse: 0.0016903240466490388, rmse: 0.04111355064512233, mae 0.025881728157401085, r2: -15.918796676091535, nrmse: 2.584134598252854\n",
      "INFO logger 2024-05-23 16:58:38,579 | helpers.py:136 | EarlyStopping counter: 27 out of 50\n",
      "INFO logger 2024-05-23 16:58:38,695 | train_utils.py:103 | Epoch 55 [Train]: loss 0.0016622344607407455, mse: 0.0016674764920026064, rmse: 0.04083474613613517, mae 0.02360398881137371, r2: 0.7501784349147675, nrmse: 1.0210326005632724\n",
      "INFO logger 2024-05-23 16:58:38,695 | train_utils.py:105 | Epoch 55 [Test]: loss 1.360048671499472e-05, mse: 0.0017119583208113909, rmse: 0.04137581806818315, mae 0.025977442041039467, r2: -14.28504350914307, nrmse: 2.952231752029369\n",
      "INFO logger 2024-05-23 16:58:38,695 | helpers.py:136 | EarlyStopping counter: 28 out of 50\n",
      "INFO logger 2024-05-23 16:58:38,813 | train_utils.py:103 | Epoch 56 [Train]: loss 0.0016479957923238968, mse: 0.0018427775939926505, rmse: 0.0429275854666047, mae 0.025007937103509903, r2: 0.6807834727257551, nrmse: 1.2158136123362187\n",
      "INFO logger 2024-05-23 16:58:38,813 | train_utils.py:105 | Epoch 56 [Test]: loss 1.3363205568050715e-05, mse: 0.0016845364589244127, rmse: 0.041043104888938566, mae 0.025401432067155838, r2: -11.796916896359212, nrmse: 2.7490514497060423\n",
      "INFO logger 2024-05-23 16:58:38,813 | helpers.py:136 | EarlyStopping counter: 29 out of 50\n",
      "INFO logger 2024-05-23 16:58:39,006 | train_utils.py:103 | Epoch 57 [Train]: loss 0.0018231702652397068, mse: 0.001729968236759305, rmse: 0.041592886852913985, mae 0.027030596509575844, r2: 0.6632580513419468, nrmse: 1.3122351974327633\n",
      "INFO logger 2024-05-23 16:58:39,006 | train_utils.py:105 | Epoch 57 [Test]: loss 1.377431291655218e-05, mse: 0.0017392050940543413, rmse: 0.04170377793503056, mae 0.030969303101301193, r2: -337.42254194967916, nrmse: 12.501128495830642\n",
      "INFO logger 2024-05-23 16:58:39,007 | helpers.py:136 | EarlyStopping counter: 30 out of 50\n",
      "INFO logger 2024-05-23 16:58:39,123 | train_utils.py:103 | Epoch 58 [Train]: loss 0.0016235255907515746, mse: 0.00167135673109442, rmse: 0.04088223001616252, mae 0.02401050366461277, r2: 0.7433017945150029, nrmse: 1.0714278273722453\n",
      "INFO logger 2024-05-23 16:58:39,123 | train_utils.py:105 | Epoch 58 [Test]: loss 1.2680722658565998e-05, mse: 0.0016003514174371958, rmse: 0.04000439247679179, mae 0.025236845016479492, r2: -27.213326925617004, nrmse: 3.9399310782018344\n",
      "INFO logger 2024-05-23 16:58:39,124 | helpers.py:136 | EarlyStopping counter: 31 out of 50\n",
      "INFO logger 2024-05-23 16:58:39,241 | train_utils.py:103 | Epoch 59 [Train]: loss 0.0017124347791544752, mse: 0.0017332549905404449, rmse: 0.04163237911218196, mae 0.02490738220512867, r2: 0.7293232954623903, nrmse: 1.1023105197311969\n",
      "INFO logger 2024-05-23 16:58:39,241 | train_utils.py:105 | Epoch 59 [Test]: loss 1.36196798827412e-05, mse: 0.001711872755549848, rmse: 0.04137478405441952, mae 0.027008220553398132, r2: -46.51066604842423, nrmse: 5.593225141725383\n",
      "INFO logger 2024-05-23 16:58:39,242 | helpers.py:136 | EarlyStopping counter: 32 out of 50\n",
      "INFO logger 2024-05-23 16:58:39,358 | train_utils.py:103 | Epoch 60 [Train]: loss 0.0018409194205539047, mse: 0.001755047240294516, rmse: 0.04189328395213863, mae 0.02480410598218441, r2: 0.7213511889705194, nrmse: 1.136665633738216\n",
      "INFO logger 2024-05-23 16:58:39,359 | train_utils.py:105 | Epoch 60 [Test]: loss 1.25596134079898e-05, mse: 0.0015864658635109663, rmse: 0.03983046401325205, mae 0.02493342198431492, r2: -28.638140057661722, nrmse: 3.409502815124153\n",
      "INFO logger 2024-05-23 16:58:39,359 | helpers.py:136 | EarlyStopping counter: 33 out of 50\n",
      "INFO logger 2024-05-23 16:58:39,476 | train_utils.py:103 | Epoch 61 [Train]: loss 0.0018294148017577205, mse: 0.0017017526552081108, rmse: 0.0412523048472217, mae 0.024393588304519653, r2: 0.7358168638025936, nrmse: 1.0718300886440293\n",
      "INFO logger 2024-05-23 16:58:39,476 | train_utils.py:105 | Epoch 61 [Test]: loss 1.3556828799287172e-05, mse: 0.0017063950654119253, rmse: 0.04130853501895129, mae 0.02679976262152195, r2: -32.48563275204128, nrmse: 4.247901332635227\n",
      "INFO logger 2024-05-23 16:58:39,476 | helpers.py:136 | EarlyStopping counter: 34 out of 50\n",
      "INFO logger 2024-05-23 16:58:39,594 | train_utils.py:103 | Epoch 62 [Train]: loss 0.0017421547466277166, mse: 0.00160073337610811, rmse: 0.040009166151122294, mae 0.02304762601852417, r2: 0.7477559835239003, nrmse: 1.041811314014887\n",
      "INFO logger 2024-05-23 16:58:39,595 | train_utils.py:105 | Epoch 62 [Test]: loss 1.2762334777453468e-05, mse: 0.0016110362485051155, rmse: 0.040137716034985296, mae 0.02530079148709774, r2: -35.76829406046827, nrmse: 4.382559564860938\n",
      "INFO logger 2024-05-23 16:58:39,595 | helpers.py:136 | EarlyStopping counter: 35 out of 50\n",
      "INFO logger 2024-05-23 16:58:39,712 | train_utils.py:103 | Epoch 63 [Train]: loss 0.0015686153401052146, mse: 0.0015566133661195636, rmse: 0.03945393980478456, mae 0.022468658164143562, r2: 0.7657770482715625, nrmse: 1.0059213574688726\n",
      "INFO logger 2024-05-23 16:58:39,712 | train_utils.py:105 | Epoch 63 [Test]: loss 1.245098365865626e-05, mse: 0.0015718985814601183, rmse: 0.03964717621042031, mae 0.02439943514764309, r2: -13.27779735923023, nrmse: 2.415100292621292\n",
      "INFO logger 2024-05-23 16:58:39,713 | helpers.py:148 | Validation loss decreased (0.000013 --> 0.000012). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:39,830 | train_utils.py:103 | Epoch 64 [Train]: loss 0.0015867253613007135, mse: 0.0015970468521118164, rmse: 0.039963068602296, mae 0.022831585258245468, r2: 0.7505803485548206, nrmse: 1.0478995581599775\n",
      "INFO logger 2024-05-23 16:58:39,830 | train_utils.py:105 | Epoch 64 [Test]: loss 1.2747095901197726e-05, mse: 0.001608005492016673, rmse: 0.04009994379069219, mae 0.02501445636153221, r2: -25.77941612210285, nrmse: 4.264115333684359\n",
      "INFO logger 2024-05-23 16:58:39,831 | helpers.py:136 | EarlyStopping counter: 1 out of 50\n",
      "INFO logger 2024-05-23 16:58:40,023 | train_utils.py:103 | Epoch 65 [Train]: loss 0.0016072011543190794, mse: 0.0016092059668153524, rmse: 0.04011490953268314, mae 0.023144034668803215, r2: 0.7581117012817579, nrmse: 1.0333790556243965\n",
      "INFO logger 2024-05-23 16:58:40,024 | train_utils.py:105 | Epoch 65 [Test]: loss 1.2663898857484697e-05, mse: 0.001598656177520752, rmse: 0.03998319869045937, mae 0.02494032122194767, r2: -23.07149969916169, nrmse: 3.586618100701165\n",
      "INFO logger 2024-05-23 16:58:40,024 | helpers.py:136 | EarlyStopping counter: 2 out of 50\n",
      "INFO logger 2024-05-23 16:58:40,142 | train_utils.py:103 | Epoch 66 [Train]: loss 0.0016227203952947219, mse: 0.0016003621276468039, rmse: 0.040004526339488186, mae 0.02286149188876152, r2: 0.7569800664391066, nrmse: 1.0240621289088019\n",
      "INFO logger 2024-05-23 16:58:40,143 | train_utils.py:105 | Epoch 66 [Test]: loss 1.2851909389487898e-05, mse: 0.0016195466741919518, rmse: 0.04024359171584902, mae 0.02501063421368599, r2: -17.83417063529849, nrmse: 3.5218482870574377\n",
      "INFO logger 2024-05-23 16:58:40,143 | helpers.py:136 | EarlyStopping counter: 3 out of 50\n",
      "INFO logger 2024-05-23 16:58:40,260 | train_utils.py:103 | Epoch 67 [Train]: loss 0.0016292829956677621, mse: 0.0015648357803002, rmse: 0.0395580052618961, mae 0.023133261129260063, r2: 0.7660894664902115, nrmse: 1.0209107524516274\n",
      "INFO logger 2024-05-23 16:58:40,260 | train_utils.py:105 | Epoch 67 [Test]: loss 1.2580650839518907e-05, mse: 0.0015876542311161757, rmse: 0.03984537904344964, mae 0.025112127885222435, r2: -27.007201755968605, nrmse: 3.7596699453832794\n",
      "INFO logger 2024-05-23 16:58:40,261 | helpers.py:136 | EarlyStopping counter: 4 out of 50\n",
      "INFO logger 2024-05-23 16:58:40,377 | train_utils.py:103 | Epoch 68 [Train]: loss 0.0016115100308133849, mse: 0.001646642223931849, rmse: 0.04057883960800073, mae 0.02363777905702591, r2: 0.7580803844245754, nrmse: 1.0196490759087184\n",
      "INFO logger 2024-05-23 16:58:40,378 | train_utils.py:105 | Epoch 68 [Test]: loss 1.3110086405908482e-05, mse: 0.0016506211832165718, rmse: 0.04062783754049152, mae 0.025079432874917984, r2: -8.174424518154968, nrmse: 2.3137559093619977\n",
      "INFO logger 2024-05-23 16:58:40,378 | helpers.py:136 | EarlyStopping counter: 5 out of 50\n",
      "INFO logger 2024-05-23 16:58:40,496 | train_utils.py:103 | Epoch 69 [Train]: loss 0.0016572433265685314, mse: 0.001583764678798616, rmse: 0.03979654104063086, mae 0.023626849055290222, r2: 0.7681170763865763, nrmse: 1.0130452021368808\n",
      "INFO logger 2024-05-23 16:58:40,497 | train_utils.py:105 | Epoch 69 [Test]: loss 1.297133304321681e-05, mse: 0.0016343218740075827, rmse: 0.04042674701243699, mae 0.025678187608718872, r2: -28.170051291799933, nrmse: 4.114439278416892\n",
      "INFO logger 2024-05-23 16:58:40,497 | helpers.py:136 | EarlyStopping counter: 6 out of 50\n",
      "INFO logger 2024-05-23 16:58:40,614 | train_utils.py:103 | Epoch 70 [Train]: loss 0.0016085103690022871, mse: 0.001578769413754344, rmse: 0.03973373143507093, mae 0.022383758798241615, r2: 0.7569987432817983, nrmse: 1.0261620905442355\n",
      "INFO logger 2024-05-23 16:58:40,615 | train_utils.py:105 | Epoch 70 [Test]: loss 1.3148026652865612e-05, mse: 0.0016545597463846207, rmse: 0.04067627989854309, mae 0.025396311655640602, r2: -9.859679816562567, nrmse: 2.014319328134573\n",
      "INFO logger 2024-05-23 16:58:40,615 | helpers.py:136 | EarlyStopping counter: 7 out of 50\n",
      "INFO logger 2024-05-23 16:58:40,733 | train_utils.py:103 | Epoch 71 [Train]: loss 0.0016185295725240712, mse: 0.0015209800330922008, rmse: 0.03899974401316245, mae 0.022512705996632576, r2: 0.7699237213205862, nrmse: 1.0147279296941218\n",
      "INFO logger 2024-05-23 16:58:40,734 | train_utils.py:105 | Epoch 71 [Test]: loss 1.2392443814110665e-05, mse: 0.0015645852545276284, rmse: 0.039554838572893054, mae 0.02471219375729561, r2: -22.579183751984296, nrmse: 3.528957138720095\n",
      "INFO logger 2024-05-23 16:58:40,734 | helpers.py:148 | Validation loss decreased (0.000012 --> 0.000012). Caching model ...\n",
      "INFO logger 2024-05-23 16:58:40,852 | train_utils.py:103 | Epoch 72 [Train]: loss 0.0016087254058897258, mse: 0.0016318013658747077, rmse: 0.0403955612149987, mae 0.023467402905225754, r2: 0.7624395943379542, nrmse: 1.0109646352893396\n",
      "INFO logger 2024-05-23 16:58:40,852 | train_utils.py:105 | Epoch 72 [Test]: loss 1.3546630842624809e-05, mse: 0.0017034451011568308, rmse: 0.041272813099628075, mae 0.025625403970479965, r2: -7.942527605021293, nrmse: 2.3488395728613605\n",
      "INFO logger 2024-05-23 16:58:40,852 | helpers.py:136 | EarlyStopping counter: 1 out of 50\n",
      "INFO logger 2024-05-23 16:58:40,970 | train_utils.py:103 | Epoch 73 [Train]: loss 0.0016244741443589975, mse: 0.0016497045289725065, rmse: 0.040616554863411376, mae 0.023813916370272636, r2: 0.7574222660853283, nrmse: 1.0295864933019487\n",
      "INFO logger 2024-05-23 16:58:40,971 | train_utils.py:105 | Epoch 73 [Test]: loss 1.3618839701109332e-05, mse: 0.0017124612350016832, rmse: 0.04138189501462787, mae 0.026270940899848938, r2: -22.61933386234009, nrmse: 3.847652851077214\n",
      "INFO logger 2024-05-23 16:58:40,971 | helpers.py:136 | EarlyStopping counter: 2 out of 50\n",
      "INFO logger 2024-05-23 16:58:41,089 | train_utils.py:103 | Epoch 74 [Train]: loss 0.0015843755238250218, mse: 0.001550911576487124, rmse: 0.03938161470136952, mae 0.022249262779951096, r2: 0.7615009786808911, nrmse: 1.022484487788159\n",
      "INFO logger 2024-05-23 16:58:41,090 | train_utils.py:105 | Epoch 74 [Test]: loss 1.2836112136672093e-05, mse: 0.0016171273309737444, rmse: 0.0402135217429877, mae 0.025132304057478905, r2: -17.412200542756036, nrmse: 3.4898313544363115\n",
      "INFO logger 2024-05-23 16:58:41,090 | helpers.py:136 | EarlyStopping counter: 3 out of 50\n",
      "INFO logger 2024-05-23 16:58:41,285 | train_utils.py:103 | Epoch 75 [Train]: loss 0.001560090167955888, mse: 0.0015553325647488236, rmse: 0.03943770486157661, mae 0.022417759522795677, r2: 0.7634952700415584, nrmse: 1.0253201911310397\n",
      "INFO logger 2024-05-23 16:58:41,285 | train_utils.py:105 | Epoch 75 [Test]: loss 1.2651079896652297e-05, mse: 0.001596739748492837, rmse: 0.03995922607474821, mae 0.024840977042913437, r2: -18.71374964364368, nrmse: 3.568411808045634\n",
      "INFO logger 2024-05-23 16:58:41,285 | helpers.py:136 | EarlyStopping counter: 4 out of 50\n",
      "INFO logger 2024-05-23 16:58:41,405 | train_utils.py:103 | Epoch 76 [Train]: loss 0.001616706007510846, mse: 0.0016331361839547753, rmse: 0.040412079678665086, mae 0.02435491979122162, r2: 0.7673709709021932, nrmse: 1.0104133479947532\n",
      "INFO logger 2024-05-23 16:58:41,405 | train_utils.py:105 | Epoch 76 [Test]: loss 1.3879748052449037e-05, mse: 0.0017426880076527596, rmse: 0.041745514820789545, mae 0.02642638608813286, r2: -13.518144872031495, nrmse: 2.949725757699761\n",
      "INFO logger 2024-05-23 16:58:41,405 | helpers.py:136 | EarlyStopping counter: 5 out of 50\n",
      "INFO logger 2024-05-23 16:58:41,526 | train_utils.py:103 | Epoch 77 [Train]: loss 0.0016252453392236168, mse: 0.0016915727173909545, rmse: 0.04112873347662136, mae 0.02431570552289486, r2: 0.7573965144510663, nrmse: 1.0142400776638907\n",
      "INFO logger 2024-05-23 16:58:41,526 | train_utils.py:105 | Epoch 77 [Test]: loss 1.3980183924673594e-05, mse: 0.0017575544770807028, rmse: 0.04192319736232797, mae 0.02645569108426571, r2: -15.500813232325367, nrmse: 3.2101963843666708\n",
      "INFO logger 2024-05-23 16:58:41,526 | helpers.py:136 | EarlyStopping counter: 6 out of 50\n",
      "INFO logger 2024-05-23 16:58:41,645 | train_utils.py:103 | Epoch 78 [Train]: loss 0.001620198374143382, mse: 0.0016284134471789002, rmse: 0.04035360513236581, mae 0.02335657924413681, r2: 0.762362076676036, nrmse: 1.01722671934177\n",
      "INFO logger 2024-05-23 16:58:41,646 | train_utils.py:105 | Epoch 78 [Test]: loss 1.398319072479502e-05, mse: 0.0017574321245774627, rmse: 0.04192173809108423, mae 0.026252811774611473, r2: -9.054837999525484, nrmse: 2.3512670584970508\n",
      "INFO logger 2024-05-23 16:58:41,646 | helpers.py:136 | EarlyStopping counter: 7 out of 50\n",
      "INFO logger 2024-05-23 16:58:41,766 | train_utils.py:103 | Epoch 79 [Train]: loss 0.0015675386762162562, mse: 0.0015909827779978514, rmse: 0.03988712546671985, mae 0.023382041603326797, r2: 0.7661570343496691, nrmse: 1.0243022881845263\n",
      "INFO logger 2024-05-23 16:58:41,766 | train_utils.py:105 | Epoch 79 [Test]: loss 1.347801681779521e-05, mse: 0.0016962162917479873, rmse: 0.04118514649419117, mae 0.025864575058221817, r2: -19.193381438479342, nrmse: 3.6135595541708607\n",
      "INFO logger 2024-05-23 16:58:41,766 | helpers.py:136 | EarlyStopping counter: 8 out of 50\n",
      "INFO logger 2024-05-23 16:58:41,885 | train_utils.py:103 | Epoch 80 [Train]: loss 0.001542414448374265, mse: 0.001610343693755567, rmse: 0.04012908787594813, mae 0.02388054132461548, r2: 0.7678291960734973, nrmse: 1.0068685306598226\n",
      "INFO logger 2024-05-23 16:58:41,885 | train_utils.py:105 | Epoch 80 [Test]: loss 1.3756179485649786e-05, mse: 0.0017296340083703399, rmse: 0.041588868803687604, mae 0.02605835534632206, r2: -12.632324733825431, nrmse: 3.015004087573629\n",
      "INFO logger 2024-05-23 16:58:41,886 | helpers.py:136 | EarlyStopping counter: 9 out of 50\n",
      "INFO logger 2024-05-23 16:58:42,005 | train_utils.py:103 | Epoch 81 [Train]: loss 0.0015560673068542856, mse: 0.0015502201858907938, rmse: 0.03937283563436591, mae 0.023058084771037102, r2: 0.7695487922731338, nrmse: 1.0150428634895698\n",
      "INFO logger 2024-05-23 16:58:42,006 | train_utils.py:105 | Epoch 81 [Test]: loss 1.300579559518166e-05, mse: 0.0016392450779676437, rmse: 0.040487591654328414, mae 0.025247847661376, r2: -20.15706937358113, nrmse: 3.8625167223468826\n",
      "INFO logger 2024-05-23 16:58:42,006 | helpers.py:136 | EarlyStopping counter: 10 out of 50\n",
      "INFO logger 2024-05-23 16:58:42,125 | train_utils.py:103 | Epoch 82 [Train]: loss 0.001569143756696153, mse: 0.0016691520577296615, rmse: 0.04085525740623429, mae 0.02439076267182827, r2: 0.767177556064407, nrmse: 1.0036056401961166\n",
      "INFO logger 2024-05-23 16:58:42,125 | train_utils.py:105 | Epoch 82 [Test]: loss 1.4261967296254608e-05, mse: 0.0017930751200765371, rmse: 0.042344717735232774, mae 0.026463836431503296, r2: -11.233026154912823, nrmse: 2.8796206229499273\n",
      "INFO logger 2024-05-23 16:58:42,126 | helpers.py:136 | EarlyStopping counter: 11 out of 50\n",
      "INFO logger 2024-05-23 16:58:42,244 | train_utils.py:103 | Epoch 83 [Train]: loss 0.0015767603501106267, mse: 0.0016449994873255491, rmse: 0.040558593261176466, mae 0.023595761507749557, r2: 0.7580494156004874, nrmse: 1.0255718097057107\n",
      "INFO logger 2024-05-23 16:58:42,244 | train_utils.py:105 | Epoch 83 [Test]: loss 1.4108944887142868e-05, mse: 0.0017740089679136872, rmse: 0.04211898583671842, mae 0.026717398315668106, r2: -23.190429065978115, nrmse: 4.069789704133354\n",
      "INFO logger 2024-05-23 16:58:42,244 | helpers.py:136 | EarlyStopping counter: 12 out of 50\n",
      "INFO logger 2024-05-23 16:58:42,440 | train_utils.py:103 | Epoch 84 [Train]: loss 0.0015581849212710865, mse: 0.0015673774760216475, rmse: 0.03959011841383715, mae 0.022946957498788834, r2: 0.770978765562334, nrmse: 1.004455081789332\n",
      "INFO logger 2024-05-23 16:58:42,440 | train_utils.py:105 | Epoch 84 [Test]: loss 1.382980307112094e-05, mse: 0.0017386112594977021, rmse: 0.04169665765379405, mae 0.02621992491185665, r2: -15.115458592513614, nrmse: 3.3000510018844462\n",
      "INFO logger 2024-05-23 16:58:42,440 | helpers.py:136 | EarlyStopping counter: 13 out of 50\n",
      "INFO logger 2024-05-23 16:58:42,558 | train_utils.py:103 | Epoch 85 [Train]: loss 0.001528579337816133, mse: 0.0016103083034977317, rmse: 0.04012864691835163, mae 0.02334476076066494, r2: 0.7700101261217333, nrmse: 1.003152768870893\n",
      "INFO logger 2024-05-23 16:58:42,559 | train_utils.py:105 | Epoch 85 [Test]: loss 1.368624051319359e-05, mse: 0.001723138033412397, rmse: 0.04151069781890443, mae 0.025772705674171448, r2: -11.537304367649813, nrmse: 2.8400895901813525\n",
      "INFO logger 2024-05-23 16:58:42,559 | helpers.py:136 | EarlyStopping counter: 14 out of 50\n",
      "INFO logger 2024-05-23 16:58:42,677 | train_utils.py:103 | Epoch 86 [Train]: loss 0.0015146669487622539, mse: 0.0015119697200134397, rmse: 0.03888405482988418, mae 0.02313404157757759, r2: 0.7769135420589575, nrmse: 1.0000620975391707\n",
      "INFO logger 2024-05-23 16:58:42,677 | train_utils.py:105 | Epoch 86 [Test]: loss 1.304821893831508e-05, mse: 0.0016440702602267265, rmse: 0.04054713627652052, mae 0.025129487738013268, r2: -11.840990218158343, nrmse: 2.9549775077563347\n",
      "INFO logger 2024-05-23 16:58:42,677 | helpers.py:136 | EarlyStopping counter: 15 out of 50\n",
      "INFO logger 2024-05-23 16:58:42,794 | train_utils.py:103 | Epoch 87 [Train]: loss 0.0015255052727974714, mse: 0.0016679834807291627, rmse: 0.04084095347478022, mae 0.02426113560795784, r2: 0.7653633218464868, nrmse: 0.9999563246006574\n",
      "INFO logger 2024-05-23 16:58:42,795 | train_utils.py:105 | Epoch 87 [Test]: loss 1.3661476727629527e-05, mse: 0.0017201447626575828, rmse: 0.04147462793874808, mae 0.025779690593481064, r2: -11.562800621639857, nrmse: 2.903763721693791\n",
      "INFO logger 2024-05-23 16:58:42,795 | helpers.py:136 | EarlyStopping counter: 16 out of 50\n",
      "INFO logger 2024-05-23 16:58:42,914 | train_utils.py:103 | Epoch 88 [Train]: loss 0.001568179975778506, mse: 0.0015408678445965052, rmse: 0.03925388954736212, mae 0.02299117110669613, r2: 0.777452337129407, nrmse: 0.9979751908330028\n",
      "INFO logger 2024-05-23 16:58:42,914 | train_utils.py:105 | Epoch 88 [Test]: loss 1.3407236429772814e-05, mse: 0.0016879414906725287, rmse: 0.041084565114803503, mae 0.025786761194467545, r2: -19.52375759819999, nrmse: 3.641421350912164\n",
      "INFO logger 2024-05-23 16:58:42,914 | helpers.py:136 | EarlyStopping counter: 17 out of 50\n",
      "INFO logger 2024-05-23 16:58:43,033 | train_utils.py:103 | Epoch 89 [Train]: loss 0.0015477042051802422, mse: 0.001696684630587697, rmse: 0.041190831875402775, mae 0.024458307772874832, r2: 0.7665705355717831, nrmse: 0.995376046563261\n",
      "INFO logger 2024-05-23 16:58:43,034 | train_utils.py:105 | Epoch 89 [Test]: loss 1.4554933091347808e-05, mse: 0.0018303690012544394, rmse: 0.04278281198395495, mae 0.02675952948629856, r2: -9.77617666351599, nrmse: 2.6481062066238623\n",
      "INFO logger 2024-05-23 16:58:43,034 | helpers.py:136 | EarlyStopping counter: 18 out of 50\n",
      "INFO logger 2024-05-23 16:58:43,154 | train_utils.py:103 | Epoch 90 [Train]: loss 0.0015357139360952885, mse: 0.0014802234945818782, rmse: 0.03847367274620241, mae 0.022989284247159958, r2: 0.7763423290571092, nrmse: 1.010057322012206\n",
      "INFO logger 2024-05-23 16:58:43,154 | train_utils.py:105 | Epoch 90 [Test]: loss 1.300821108546119e-05, mse: 0.0016384596237912774, rmse: 0.040477890555107705, mae 0.02536558173596859, r2: -18.60340734735073, nrmse: 3.629567677609311\n",
      "INFO logger 2024-05-23 16:58:43,155 | helpers.py:136 | EarlyStopping counter: 19 out of 50\n",
      "INFO logger 2024-05-23 16:58:43,273 | train_utils.py:103 | Epoch 91 [Train]: loss 0.0015207838980216388, mse: 0.001682564034126699, rmse: 0.0410190691523674, mae 0.024591263383626938, r2: 0.7651595545061418, nrmse: 1.0037851534531086\n",
      "INFO logger 2024-05-23 16:58:43,274 | train_utils.py:105 | Epoch 91 [Test]: loss 1.391999384188175e-05, mse: 0.0017516309162601829, rmse: 0.04185248996487763, mae 0.025822525843977928, r2: -4.21773411690056, nrmse: 1.5400646414216606\n",
      "INFO logger 2024-05-23 16:58:43,274 | helpers.py:136 | EarlyStopping counter: 20 out of 50\n",
      "INFO logger 2024-05-23 16:58:43,393 | train_utils.py:103 | Epoch 92 [Train]: loss 0.0015941007271299725, mse: 0.0016882767667993903, rmse: 0.041088645229544744, mae 0.024663623422384262, r2: 0.7661718875272634, nrmse: 1.0159759444156522\n",
      "INFO logger 2024-05-23 16:58:43,393 | train_utils.py:105 | Epoch 92 [Test]: loss 1.4726497278526992e-05, mse: 0.001850257278420031, rmse: 0.043014617032120964, mae 0.02705403044819832, r2: -14.762264745531088, nrmse: 3.253961170751374\n",
      "INFO logger 2024-05-23 16:58:43,394 | helpers.py:136 | EarlyStopping counter: 21 out of 50\n",
      "INFO logger 2024-05-23 16:58:43,588 | train_utils.py:103 | Epoch 93 [Train]: loss 0.0015669850730096926, mse: 0.0018191516865044832, rmse: 0.04265151446906057, mae 0.025728488340973854, r2: 0.764235676435999, nrmse: 1.0042786504788084\n",
      "INFO logger 2024-05-23 16:58:43,588 | train_utils.py:105 | Epoch 93 [Test]: loss 1.5493079237721597e-05, mse: 0.001948141842149198, rmse: 0.044137759822505694, mae 0.027497291564941406, r2: -8.498191666649443, nrmse: 2.4281780266399666\n",
      "INFO logger 2024-05-23 16:58:43,589 | helpers.py:136 | EarlyStopping counter: 22 out of 50\n",
      "INFO logger 2024-05-23 16:58:43,708 | train_utils.py:103 | Epoch 94 [Train]: loss 0.0015793152661413038, mse: 0.001680575544014573, rmse: 0.04099482338069739, mae 0.02497447095811367, r2: 0.7668642724307407, nrmse: 1.0215913247625537\n",
      "INFO logger 2024-05-23 16:58:43,708 | train_utils.py:105 | Epoch 94 [Test]: loss 1.553412244657915e-05, mse: 0.001949969446286559, rmse: 0.04415845837760371, mae 0.028219517320394516, r2: -28.040633481721102, nrmse: 4.537817883345575\n",
      "INFO logger 2024-05-23 16:58:43,709 | helpers.py:136 | EarlyStopping counter: 23 out of 50\n",
      "INFO logger 2024-05-23 16:58:43,828 | train_utils.py:103 | Epoch 95 [Train]: loss 0.001533013584564689, mse: 0.0017389645799994469, rmse: 0.04170089423500948, mae 0.02509469725191593, r2: 0.7612102202948527, nrmse: 0.999005217858537\n",
      "INFO logger 2024-05-23 16:58:43,829 | train_utils.py:105 | Epoch 95 [Test]: loss 1.5071884858999292e-05, mse: 0.0018949279328808188, rmse: 0.043530769955065336, mae 0.02775595150887966, r2: -14.813390397143959, nrmse: 2.702491692078009\n",
      "INFO logger 2024-05-23 16:58:43,829 | helpers.py:136 | EarlyStopping counter: 24 out of 50\n",
      "INFO logger 2024-05-23 16:58:43,948 | train_utils.py:103 | Epoch 96 [Train]: loss 0.001573284266521304, mse: 0.0016082001384347677, rmse: 0.04010237073334652, mae 0.02366703189909458, r2: 0.773304058532068, nrmse: 1.003818986630197\n",
      "INFO logger 2024-05-23 16:58:43,948 | train_utils.py:105 | Epoch 96 [Test]: loss 1.4884770716464267e-05, mse: 0.0018693495076149702, rmse: 0.04323597469255169, mae 0.027207907289266586, r2: -18.569261065274834, nrmse: 3.7590417247490087\n",
      "INFO logger 2024-05-23 16:58:43,948 | helpers.py:136 | EarlyStopping counter: 25 out of 50\n",
      "INFO logger 2024-05-23 16:58:44,068 | train_utils.py:103 | Epoch 97 [Train]: loss 0.0015104029883987941, mse: 0.0016770695801824331, rmse: 0.04095204000025436, mae 0.02362191118299961, r2: 0.7287461454684923, nrmse: 1.0826531147334855\n",
      "INFO logger 2024-05-23 16:58:44,068 | train_utils.py:105 | Epoch 97 [Test]: loss 1.335422571732156e-05, mse: 0.0016796322306618094, rmse: 0.040983316491736116, mae 0.02558770403265953, r2: -12.950264662389731, nrmse: 2.989422636925136\n",
      "INFO logger 2024-05-23 16:58:44,068 | helpers.py:136 | EarlyStopping counter: 26 out of 50\n",
      "INFO logger 2024-05-23 16:58:44,185 | train_utils.py:103 | Epoch 98 [Train]: loss 0.0016740942588766366, mse: 0.0016059415647760034, rmse: 0.040074200737831356, mae 0.023658068850636482, r2: 0.7457825075611118, nrmse: 1.0635946188517678\n",
      "INFO logger 2024-05-23 16:58:44,186 | train_utils.py:105 | Epoch 98 [Test]: loss 1.2596797465948573e-05, mse: 0.0015894619282335043, rmse: 0.039868056489293584, mae 0.024641944095492363, r2: -11.093651896067133, nrmse: 2.6649891916369053\n",
      "INFO logger 2024-05-23 16:58:44,186 | helpers.py:136 | EarlyStopping counter: 27 out of 50\n",
      "INFO logger 2024-05-23 16:58:44,304 | train_utils.py:103 | Epoch 99 [Train]: loss 0.0016561282364120924, mse: 0.0016556335613131523, rmse: 0.040689477279920325, mae 0.023850370198488235, r2: 0.757169791236352, nrmse: 1.0282537898634434\n",
      "INFO logger 2024-05-23 16:58:44,304 | train_utils.py:105 | Epoch 99 [Test]: loss 1.2551806135271943e-05, mse: 0.0015841471031308174, rmse: 0.03980134549397567, mae 0.02431240677833557, r2: -8.18370517605888, nrmse: 1.8062927535561515\n",
      "INFO logger 2024-05-23 16:58:44,305 | helpers.py:136 | EarlyStopping counter: 28 out of 50\n",
      "INFO logger 2024-05-23 16:58:44,422 | train_utils.py:103 | Epoch 100 [Train]: loss 0.0015523402960456604, mse: 0.0015168616082519293, rmse: 0.038946907556979785, mae 0.022282341495156288, r2: 0.768680955207838, nrmse: 0.9942831665581883\n",
      "INFO logger 2024-05-23 16:58:44,423 | train_utils.py:105 | Epoch 100 [Test]: loss 1.2917934620088479e-05, mse: 0.0016294404631480575, rmse: 0.040366328333749375, mae 0.024811554700136185, r2: -8.849353684194964, nrmse: 2.424056302813325\n",
      "INFO logger 2024-05-23 16:58:44,423 | helpers.py:136 | EarlyStopping counter: 29 out of 50\n",
      "INFO logger 2024-05-23 16:58:44,539 | train_utils.py:103 | Epoch 101 [Train]: loss 0.00171369482014534, mse: 0.001606385805644095, rmse: 0.040079743083558994, mae 0.023727089166641235, r2: 0.761471058736773, nrmse: 1.0044967876862607\n",
      "INFO logger 2024-05-23 16:58:44,539 | train_utils.py:105 | Epoch 101 [Test]: loss 1.2772693996568216e-05, mse: 0.0016124446410685778, rmse: 0.040155256705300464, mae 0.025251343846321106, r2: -21.818824986187572, nrmse: 2.580804990970014\n",
      "INFO logger 2024-05-23 16:58:44,539 | helpers.py:136 | EarlyStopping counter: 30 out of 50\n",
      "INFO logger 2024-05-23 16:58:44,733 | train_utils.py:103 | Epoch 102 [Train]: loss 0.0016261618304143181, mse: 0.0015932621899992228, rmse: 0.03991568851966884, mae 0.0243061650544405, r2: 0.7527462710743497, nrmse: 1.048622852595838\n",
      "INFO logger 2024-05-23 16:58:44,733 | train_utils.py:105 | Epoch 102 [Test]: loss 1.3250877121831045e-05, mse: 0.0016742588486522436, rmse: 0.04091770825268986, mae 0.026173461228609085, r2: -28.68095673468209, nrmse: 3.395535588244526\n",
      "INFO logger 2024-05-23 16:58:44,733 | helpers.py:136 | EarlyStopping counter: 31 out of 50\n",
      "INFO logger 2024-05-23 16:58:44,853 | train_utils.py:103 | Epoch 103 [Train]: loss 0.001667768294705744, mse: 0.001542666694149375, rmse: 0.039276795874273844, mae 0.022957053035497665, r2: 0.7716094816041031, nrmse: 1.0061573986059693\n",
      "INFO logger 2024-05-23 16:58:44,854 | train_utils.py:105 | Epoch 103 [Test]: loss 1.250020257600349e-05, mse: 0.001578651717863977, rmse: 0.03973225034986034, mae 0.024543095380067825, r2: -15.132648746967286, nrmse: 3.064833600684295\n",
      "INFO logger 2024-05-23 16:58:44,854 | helpers.py:136 | EarlyStopping counter: 32 out of 50\n",
      "INFO logger 2024-05-23 16:58:44,973 | train_utils.py:103 | Epoch 104 [Train]: loss 0.001670106172622222, mse: 0.0016054410953074694, rmse: 0.04006795596617663, mae 0.02377353422343731, r2: 0.7618445728367984, nrmse: 1.0132670433530686\n",
      "INFO logger 2024-05-23 16:58:44,974 | train_utils.py:105 | Epoch 104 [Test]: loss 1.3605328290369252e-05, mse: 0.0017099946271628141, rmse: 0.04135208129179007, mae 0.02624652162194252, r2: -11.545854869150395, nrmse: 1.8581050127641254\n",
      "INFO logger 2024-05-23 16:58:44,974 | helpers.py:136 | EarlyStopping counter: 33 out of 50\n",
      "INFO logger 2024-05-23 16:58:45,093 | train_utils.py:103 | Epoch 105 [Train]: loss 0.0016546726892133741, mse: 0.0016787175554782152, rmse: 0.04097215585587626, mae 0.02424033358693123, r2: 0.7599924146434193, nrmse: 1.026919780812376\n",
      "INFO logger 2024-05-23 16:58:45,093 | train_utils.py:105 | Epoch 105 [Test]: loss 1.4505807272218473e-05, mse: 0.0018231726717203856, rmse: 0.04269862611045448, mae 0.026784192770719528, r2: -12.870155981258705, nrmse: 3.1078914677391993\n",
      "INFO logger 2024-05-23 16:58:45,093 | helpers.py:136 | EarlyStopping counter: 34 out of 50\n",
      "INFO logger 2024-05-23 16:58:45,211 | train_utils.py:103 | Epoch 106 [Train]: loss 0.0015547836409559538, mse: 0.001563752070069313, rmse: 0.03954430515345178, mae 0.022947896271944046, r2: 0.774641044294861, nrmse: 0.9918264329116309\n",
      "INFO logger 2024-05-23 16:58:45,212 | train_utils.py:105 | Epoch 106 [Test]: loss 1.3780671805660757e-05, mse: 0.0017348902765661478, rmse: 0.041652014075746056, mae 0.02605971321463585, r2: -8.486858876336381, nrmse: 2.05873934884884\n",
      "INFO logger 2024-05-23 16:58:45,212 | helpers.py:136 | EarlyStopping counter: 35 out of 50\n",
      "INFO logger 2024-05-23 16:58:45,330 | train_utils.py:103 | Epoch 107 [Train]: loss 0.0014892704632582662, mse: 0.001473250100389123, rmse: 0.038382940225953545, mae 0.02193036675453186, r2: 0.7805857965927351, nrmse: 0.992139804482721\n",
      "INFO logger 2024-05-23 16:58:45,330 | train_utils.py:105 | Epoch 107 [Test]: loss 1.304122682814677e-05, mse: 0.0016444167122244835, rmse: 0.0405514082643807, mae 0.02535378374159336, r2: -15.475145569738396, nrmse: 3.224015044209769\n",
      "INFO logger 2024-05-23 16:58:45,331 | helpers.py:136 | EarlyStopping counter: 36 out of 50\n",
      "INFO logger 2024-05-23 16:58:45,449 | train_utils.py:103 | Epoch 108 [Train]: loss 0.001466304646338929, mse: 0.0014583510346710682, rmse: 0.03818836255550987, mae 0.02178727649152279, r2: 0.7866841334904089, nrmse: 0.9744309284859264\n",
      "INFO logger 2024-05-23 16:58:45,449 | train_utils.py:105 | Epoch 108 [Test]: loss 1.2677690498966572e-05, mse: 0.0015995384892448783, rmse: 0.03999423069950062, mae 0.024690190330147743, r2: -11.09739003984329, nrmse: 2.667733405488455\n",
      "INFO logger 2024-05-23 16:58:45,449 | helpers.py:136 | EarlyStopping counter: 37 out of 50\n",
      "INFO logger 2024-05-23 16:58:45,568 | train_utils.py:103 | Epoch 109 [Train]: loss 0.0014892062418914785, mse: 0.0015279246727004647, rmse: 0.03908867703952725, mae 0.022233180701732635, r2: 0.7662876851331198, nrmse: 1.0030353314589173\n",
      "INFO logger 2024-05-23 16:58:45,569 | train_utils.py:105 | Epoch 109 [Test]: loss 1.2846332644548115e-05, mse: 0.0016209951136261225, rmse: 0.04026158359560789, mae 0.025114193558692932, r2: -14.097638518778572, nrmse: 3.0065780941183062\n",
      "INFO logger 2024-05-23 16:58:45,569 | helpers.py:136 | EarlyStopping counter: 38 out of 50\n",
      "INFO logger 2024-05-23 16:58:45,688 | train_utils.py:103 | Epoch 110 [Train]: loss 0.001529863683043554, mse: 0.0015227084513753653, rmse: 0.03902189707555702, mae 0.022294335067272186, r2: 0.7775691476781812, nrmse: 0.9894256035417373\n",
      "INFO logger 2024-05-23 16:58:45,689 | train_utils.py:105 | Epoch 110 [Test]: loss 1.3030933390496767e-05, mse: 0.0016445145010948181, rmse: 0.04055261398596665, mae 0.024945516139268875, r2: -10.66556870539351, nrmse: 2.816091099208465\n",
      "INFO logger 2024-05-23 16:58:45,689 | helpers.py:136 | EarlyStopping counter: 39 out of 50\n",
      "INFO logger 2024-05-23 16:58:45,883 | train_utils.py:103 | Epoch 111 [Train]: loss 0.001525292583442764, mse: 0.0015422506257891655, rmse: 0.03927149889919107, mae 0.023319195955991745, r2: 0.7714417790703155, nrmse: 1.0115796507759713\n",
      "INFO logger 2024-05-23 16:58:45,883 | train_utils.py:105 | Epoch 111 [Test]: loss 1.3263491419762134e-05, mse: 0.001672098645940423, rmse: 0.04089130281539612, mae 0.025650596246123314, r2: -16.483536840334704, nrmse: 3.3963611640429026\n",
      "INFO logger 2024-05-23 16:58:45,883 | helpers.py:136 | EarlyStopping counter: 40 out of 50\n",
      "INFO logger 2024-05-23 16:58:46,004 | train_utils.py:103 | Epoch 112 [Train]: loss 0.0015069458768689507, mse: 0.0015287308488041162, rmse: 0.039098987823268726, mae 0.02250700443983078, r2: 0.7711109582470289, nrmse: 1.002900446800862\n",
      "INFO logger 2024-05-23 16:58:46,004 | train_utils.py:105 | Epoch 112 [Test]: loss 1.2842250066436283e-05, mse: 0.0016208682209253311, rmse: 0.040260007711441524, mae 0.02508019283413887, r2: -11.555893922280582, nrmse: 2.4127485044912476\n",
      "INFO logger 2024-05-23 16:58:46,005 | helpers.py:136 | EarlyStopping counter: 41 out of 50\n",
      "INFO logger 2024-05-23 16:58:46,125 | train_utils.py:103 | Epoch 113 [Train]: loss 0.0015244734228851253, mse: 0.0014941546833142638, rmse: 0.038654297087313126, mae 0.021972037851810455, r2: 0.7760437650807068, nrmse: 1.0005645654562112\n",
      "INFO logger 2024-05-23 16:58:46,125 | train_utils.py:105 | Epoch 113 [Test]: loss 1.2877580584830208e-05, mse: 0.001623940421268344, rmse: 0.040298144141738636, mae 0.025005236268043518, r2: -16.17141972769784, nrmse: 3.4392772878077165\n",
      "INFO logger 2024-05-23 16:58:46,125 | helpers.py:136 | EarlyStopping counter: 42 out of 50\n",
      "INFO logger 2024-05-23 16:58:46,245 | train_utils.py:103 | Epoch 114 [Train]: loss 0.0014897250027155848, mse: 0.0015260587679222226, rmse: 0.03906480216156512, mae 0.022372789680957794, r2: 0.775606791632503, nrmse: 1.0055172783958894\n",
      "INFO logger 2024-05-23 16:58:46,246 | train_utils.py:105 | Epoch 114 [Test]: loss 1.285527577509352e-05, mse: 0.0016227827873080969, rmse: 0.04028377821540697, mae 0.024697549641132355, r2: -9.384086401040403, nrmse: 2.5920882446793883\n",
      "INFO logger 2024-05-23 16:58:46,246 | helpers.py:136 | EarlyStopping counter: 43 out of 50\n",
      "INFO logger 2024-05-23 16:58:46,366 | train_utils.py:103 | Epoch 115 [Train]: loss 0.0014932050417819694, mse: 0.0014965240843594074, rmse: 0.03868493355764499, mae 0.022214218974113464, r2: 0.7814680589488034, nrmse: 0.9885496322997028\n",
      "INFO logger 2024-05-23 16:58:46,367 | train_utils.py:105 | Epoch 115 [Test]: loss 1.3067365174007476e-05, mse: 0.0016478704055771232, rmse: 0.040593970064248745, mae 0.025067901238799095, r2: -10.415155393209433, nrmse: 2.757084120041467\n",
      "INFO logger 2024-05-23 16:58:46,367 | helpers.py:136 | EarlyStopping counter: 44 out of 50\n",
      "INFO logger 2024-05-23 16:58:46,486 | train_utils.py:103 | Epoch 116 [Train]: loss 0.0014874961444484355, mse: 0.0016165856504812837, rmse: 0.04020678612474869, mae 0.023579491302371025, r2: 0.7729613970663511, nrmse: 0.9956341930380347\n",
      "INFO logger 2024-05-23 16:58:46,486 | train_utils.py:105 | Epoch 116 [Test]: loss 1.3472347017186993e-05, mse: 0.0016999241197481751, rmse: 0.04123013606269297, mae 0.02532792091369629, r2: -8.214878173749725, nrmse: 2.3726031929644833\n",
      "INFO logger 2024-05-23 16:58:46,486 | helpers.py:136 | EarlyStopping counter: 45 out of 50\n",
      "INFO logger 2024-05-23 16:58:46,606 | train_utils.py:103 | Epoch 117 [Train]: loss 0.0015488622785321854, mse: 0.0016113541787490249, rmse: 0.04014167633207443, mae 0.02395952306687832, r2: 0.7756021136347184, nrmse: 0.9962039268297804\n",
      "INFO logger 2024-05-23 16:58:46,606 | train_utils.py:105 | Epoch 117 [Test]: loss 1.4435366641632036e-05, mse: 0.001817280426621437, rmse: 0.042629572207816456, mae 0.026663461700081825, r2: -11.021162590148709, nrmse: 2.7930849449238906\n",
      "INFO logger 2024-05-23 16:58:46,607 | helpers.py:136 | EarlyStopping counter: 46 out of 50\n",
      "INFO logger 2024-05-23 16:58:46,727 | train_utils.py:103 | Epoch 118 [Train]: loss 0.0014936201357375804, mse: 0.0016794580733403563, rmse: 0.04098119170229626, mae 0.024669038131833076, r2: 0.7705748219553069, nrmse: 0.9853101432606745\n",
      "INFO logger 2024-05-23 16:58:46,728 | train_utils.py:105 | Epoch 118 [Test]: loss 1.4315112847943752e-05, mse: 0.001803683815523982, rmse: 0.04246979886370999, mae 0.026739344000816345, r2: -11.720016607420822, nrmse: 1.730443993917642\n",
      "INFO logger 2024-05-23 16:58:46,728 | helpers.py:136 | EarlyStopping counter: 47 out of 50\n",
      "INFO logger 2024-05-23 16:58:46,849 | train_utils.py:103 | Epoch 119 [Train]: loss 0.0015661481574366113, mse: 0.001610717736184597, rmse: 0.04013374809539469, mae 0.02384667843580246, r2: 0.7768752798421956, nrmse: 0.9972643298672318\n",
      "INFO logger 2024-05-23 16:58:46,850 | train_utils.py:105 | Epoch 119 [Test]: loss 1.4901717400385274e-05, mse: 0.0018758965888991952, rmse: 0.04331162186872243, mae 0.027251139283180237, r2: -12.236239587838021, nrmse: 2.90767158316123\n",
      "INFO logger 2024-05-23 16:58:46,850 | helpers.py:136 | EarlyStopping counter: 48 out of 50\n",
      "INFO logger 2024-05-23 16:58:47,047 | train_utils.py:103 | Epoch 120 [Train]: loss 0.0015146991898629578, mse: 0.001785983331501484, rmse: 0.04226089600921263, mae 0.025991514325141907, r2: 0.7629810088727644, nrmse: 1.000106595976122\n",
      "INFO logger 2024-05-23 16:58:47,047 | train_utils.py:105 | Epoch 120 [Test]: loss 1.550713196268839e-05, mse: 0.0019496388267725706, rmse: 0.044154714660753616, mae 0.027711963281035423, r2: -7.71219181508463, nrmse: 2.071567382646051\n",
      "INFO logger 2024-05-23 16:58:47,047 | helpers.py:136 | EarlyStopping counter: 49 out of 50\n",
      "INFO logger 2024-05-23 16:58:47,167 | train_utils.py:103 | Epoch 121 [Train]: loss 0.0015419777469422877, mse: 0.0015019697602838278, rmse: 0.038755254615133516, mae 0.02302910014986992, r2: 0.7791963911666949, nrmse: 1.0067940434495641\n",
      "INFO logger 2024-05-23 16:58:47,168 | train_utils.py:105 | Epoch 121 [Test]: loss 1.3522353907979002e-05, mse: 0.0017052069306373596, rmse: 0.041294151288497984, mae 0.025609910488128662, r2: -12.01530573330199, nrmse: 2.98846640597176\n",
      "INFO logger 2024-05-23 16:58:47,168 | helpers.py:136 | EarlyStopping counter: 50 out of 50\n",
      "INFO logger 2024-05-23 16:58:47,168 | train_utils.py:123 | Early Stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO logger 2024-05-23 16:58:47,278 | train_utils.py:146 | Best Loss: 1.2392443814110665e-05, Best epoch: 121\n"
     ]
    }
   ],
   "source": [
    "trained_model = fit(model, X_train, y_train, X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "a39106e1a9d6d153b7400628e7589ff266b5caee5b0db427f0903be982155882"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
